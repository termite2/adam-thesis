\chapter{Solving Games Efficiently}
\label{ch:solving}

We have a formalism for the driver synthesis problem as a game. A practical driver synthesis tool using the game formalism must be able to solve and find strategies for these games for real device and operating system specifications in a reasonable amount of time. The principle challenge of this work is creating a synthesis algorithm that scales well enough to handle the large state machines of real device and operating system specifications. 

The straightforward symbolic solver that uses BDDs as the symbolic data structure is remarkably efficient. In fact, it is the current state of the art in reactive synthesis. I will use this as the starting point for my description of Termite's game solver.

I begin by describing my entry to the reactive synthesis competition in 2014, appropriately named "Simple BDD Solver". This solver won the sequential realizability category.

Next, I introduce abstraction, a technique to increase the scalability of the basic symbolic algorithm by reducing the effective size of the state space that the algorithm must operate on. The cost of reducing the size of the state space is that the abstracted game is represented with less precision and is often not precise enough to solve the original game. To counter this, the abstraction needs to be \emph{refined}, i.e.\ the precision of the abstraction needs to be increased. This is performed in an \emph{abstraction-refinement loop}. Ideally, this loop results in an abstraction just precise enough to solve the game, but coarse enough that solving it is tractable.

I give an abstraction-refinement algorithm that uses \emph{variable abstraction}, a technique for reducing the state space of the game by eliminating a subset of the state variables from the game. I then build on this to arrive at an algorithm that performs \emph{predicate abstraction}, a technique that, instead of representing the state space using state variables, represents relationships between state variables that capture key properties that are likely to be of importance in solving the game. This representation is usually far more compact. This is the synthesis algorithm that Termite uses.

To simplify the presentation, with the exception of Section~\ref{sec:syntcomp}, we assume that all games are turn based.

\section{Synthesis Competition}
\label{sec:syntcomp}

The Reactive Synthesis Competition is a competition for reactive synthesis tools inspired by competitions in other fields such as the SAT competition and the Hardware Model Checking Competition. The competition had four tracks:
\begin{itemize}
    \item Sequential realizability
    \item Parallel realizability
    \item Sequential synthesis
    \item Parallel synthesis
\end{itemize}

The tools were required to solve safety games given in an extension of the AIGER format \cite{aiger}. 

Entrants in the synthesis categories were required to produce an implementation of a controller that enforced the safety condition, also given in extended AIGER format. Entrants in the realizability category were only required to determine if the safety game was winnable.

The Synthesis Competition was run as a satellite event to the CAV conference and Kurt Godel medals in silver were awarded to the winners of each category.

\input{syntcomp}

\section{Three Valued Abstraction-Refinement}
An abstraction is a simplification of the original transition system. An abstraction is used when the game is too large to be solved. Ideally, an abstraction is both small enough to be solved and detailed enough to gain some additional information about the properties of the system. 

One common use of an abstraction is in an abstraction-refinement loop. In an abstraction refinement loop, an initial simple abstraction is found and is solved. Then, the results of the abstraction are used to refine the abstraction, ie\. to build another system model that contains slightly more detail than the original abstraction. This is repeated in a loop until the original game is solved. It is often possible to solve the original game with a far less detailed abstraction that the original system. 

Finding an abstraction that is simultaneously small and useful for making progress in solving the game is a difficult task and is what will be dealt with in the following sections. We start with earlier work on three valued abstraction refinement. 

\subsection{Three valued abstraction refinement}
\label{sec:three_val_abs_ref}

The idea is that, given an abstraction, we classify states into one of three categories: winning, losing, and unknown. If we discover that the entire initial set is winning, we know that the original game is winning and we can terminate. Dually, if we discover any initial state that is losing, we know that the entire initial set can never be winning, hence the game is losing and we can terminate. 

At termination, either 
\begin{itemize}
\item all of the initial states are classified as winning (and the other states need not be classified), or
\item one of the initial states is classified as losing (again, no other states need to be classified)
\end{itemize}

This additional imprecision often allows us to use a less precise abstraction compared to the original algorithm where all states are exactly classified. The use of a coarser abstraction is usually computationally more efficient. If none of the termination conditions are met then we need to refine the abstraction. A correct abstraction refinement scheme will guarantee that one of the termination conditions is eventually met after enough refinements are performed. A good abstraction refinement scheme will ensure that when the algorithm terminates the abstraction is not unnecessarily fine.

\subsection{Abstraction}
\label{sec:abstraction_def}

An abstraction of a game structure $G$ is a tuple $\langle V, \concrete{}\rangle$, where 
\begin{itemize}
    \item $V$ is a finite set of abstract states and 
    \item $\concrete{} : V \rightarrow 2^S $ is the \emph{concretisation function}, which takes an abstract state and returns the possibly empty set of concrete states that the abstract state corresponds to.  
\end{itemize}
        
We require that 
\begin{itemize}
    \item $\bigcup_{v\in V}\concrete{v} = S$, ie.\ the abstraction covers the entire state space. 
    \item $\concrete{v_1}\cap \concrete{v_2} = \emptyset$ for any $v_1$ and $v_2$, $v_1 \neq v_2$, ie.\ the abstraction partitions the state space.
\end{itemize}

In the case when $\concrete{v} = \emptyset$ the abstract state $v$ is said to be \emph{inconsistent}. We extend the $\concrete{}$ operator to sets of abstract states as follows: for $U\subseteq V$: $\concrete{U} = \bigcup_{u\in U}\concrete{u}$.

\subsection{Algorithm}
\label{sec:threeval_generic}

In this section we present a modified version of the three-valued abstraction refinement technique of de~Alfaro and Roy~\cite{Alfaro_Roy_07}. To simplify the presentation, we focus on solving reachability games. 

We start by defining two versions of the abstraction operator: the \emph{may-abstraction} $\abstractm{}$ and the \emph{must-abstraction} $\abstractM{}$. For a set of concrete states $T \subseteq S$:

\begin{equation}
\abstractm{T} = \{v\in V\mid \concrete{v} \cap T \neq \emptyset\} 
\end{equation}

Intuitively, this returns the set of abstract states which, when concretised, overlap some element of the set to be abstracted.

\begin{equation}
\abstractM{T} = \{v\in V\mid \concrete{v} \subseteq T \}
\end{equation}

Intuitively, this returns the set of abstract states which, when concretised, are contained within the set to be abstracted.

We say that an abstraction is \emph{precise} for a set $T\subseteq S$ if :

\begin{equation}
\concrete{(\abstractm{T})} = \concrete{(\abstractM{T})}
\end{equation}

Intuitively, this means that there are no abstract states that, when concretised, contain states that within $T$ and states that are outside $T$.

Next, we define may and must versions of the abstract controllable predecessor operator:

\begin{equation}
    Cpre_i^m(U) = \abstractm{Cpre_i(\concrete{U})}
    \label{eqn:def_cpre_m}
\end{equation}

Intuitively, this returns the set of abstract states such that, when concretised, we can force execution from at least one concrete state into the concretisation of $U$.

\begin{equation}
    Cpre_i^M(U) = \abstractM{Cpre_i(\concrete{U})}
    \label{eqn:def_cpre_M}
\end{equation}

Intuitively, this returns the set of abstract states such that, when concretised, we can force execution from all of the concrete states into the concretisation of $U$.

These operators have the property:

\begin{equation}
\concrete{Cpre_i^M(U)} \subseteq Cpre_i(\concrete{U}) \subseteq \concrete{Cpre_i^m(U)}
\end{equation}

And therefore:

\begin{equation}
\label{eqn:cpre_inclusion}
\concrete{\reach(\abstractM{T}, Cpre_i^M)} \subseteq \reach(T, Cpre_i) \subseteq \concrete{\reach(\abstractm{T}, Cpre_i^m)}
\end{equation}

We denote $\reach(\abstractM{T}, Cpre_i^M)$ as $W^M$ and refer to it as the \emph{must-winning} region and we denote $\reach(\abstractm{T}, Cpre_i^m)$ as $W^m$ and refer to it as the \emph{may-winning} region.

\begin{figure}[t]
\centering
\includegraphics[width=0.85\linewidth]{diagrams/threeValOverview.pdf}
\caption{Overview of three valued abstraction-refinement}
\label{fig:three_val_overview}
\end{figure}

Figure~\ref{fig:three_val_overview} illustrates the main idea of three valued abstraction refinement, which is presented in algorithm~\ref{alg:generic}. The winning region, in grey, is overapproximated by the may-winning set in white and underapproximated by the must-winning set in dark grey. The abstraction-refinement loop progressively brings $W^m$ and $W^M$ closer together until the game outcome can be determined.

At every iteration, the algorithm computes the must-winning set $W^M$ that underapproximates, and the may-winning set $W^m$ that overapproximates the true winning set (lines~\ref{a:generic:l:M}--\ref{a:generic:l:m}). The algorithm terminates if the must-winning set contains the entire initial set or the may-winning set has shrunk beyond the initial set (lines~\ref{a:generic:l:yes}--\ref{a:generic:l:no}).  Otherwise, the algorithm attempts to refine the abstraction in a way that the must-winning set will be expanded in the next iteration when the game is re-solved.

\begin{algorithm}
\caption{Three-valued abstraction refinement for games.}
\label{alg:generic}

\begin{algorithmic}[1]

\Require A game structure $G = \langle S, L, I, \tau_1, \tau_2, \delta \rangle$, a set of target states $T\subseteq S$, and an initial abstraction $\alpha=\langle V, \concrete{} \rangle$ that is precise for $T$, $I$, and $\tau_i$.

\Ensure {\it Yes} if $I \subseteq \reach(T, Cpre_1)$, and {\it No} otherwise.

\Function{Solve}{$transitionRelation$, $goal$}
    \Loop
        \State $W^M \gets \reach(\abstractM{T}, Cpre_1^M)$ \label{a:generic:l:M}
        \State $W^m \gets \reach(\abstractm{T}, Cpre_1^m)$ \label{a:generic:l:m}
        \If{$\abstractM{I} \subseteq W^M$} \label{alg:tvg:tc1}
            \State\Return Yes \label{a:generic:l:yes}
        \ElsIf{$\abstractM{I} \nsubseteq W^m$} \label{alg:tvg:tc2}
            \State\Return No \label{a:generic:l:no}
        \Else       
            \State$\Call{refineAbstraction}{W^M}$
        \EndIf
    \EndLoop
\EndFunction

\end{algorithmic}
\end{algorithm}

To expand the must-winning set we attempt to perform a refinement of the abstraction. This means that we split one or more of the abstract states in $V$ in two. 

We observe that if there exists a winning concrete state $c$ then there also exists a chain of winning concrete states from $c$ to the goal. If $c$ is not part of $\concrete{W^M} \cup goal$, then, some point, this chain must enter $\concrete{W^M} \cup goal$. Therefore, if there exists some concrete winning state that is not part of $\concrete{W^M} \cup goal$ then there also exists one with a transition into $\concrete{W^M} \cup goal$. 

Thus, we can narrow down our search for abstract states to split to those that have at least one concrete state with a transition into $W^M$, excluding $W^M$ as these states are already must-winning so splitting them will not achieve anything. Thus, we look in $Cpre_1^m(W^M \cup goal)\setminus W^M$, i.e.\ the set of all may-predecessors of the must-winning set. 

If we find an abstract state within this set for which from a subset of concrete states it is possible to force execution into $\concrete{W^M}$ then we can partition this abstract state in two such that those winning concrete states form one partition while the remaining states for the other partition.

The former partition, $p$, consists entirely of winning concrete states. Furthermore, it is on the boundary of the must-winning set so it will become part of $W^M$ when the game is solved again with the refined abstraction.

Each time a refinement is made, $\concrete{W^M}$ grows. If the concrete state space is finite $\concrete{W^M}$ can only grow so much so it must reach a fixed point (that may contain the entire concrete state space). When $W^M$ can no longer grow it is because there are no winning states at the boundary. Thus there are no winning states that are not part of $W^M$ and $W^M$ must be the exact winning set. Furthermore, $W^m$ must be equal to $W^M$ as if there are and any potential winning states that are not in $W^M$ then there must be some at the boundary and we know that there are none of those. Therefore one of the two termination conditions (lines~\ref{alg:tvg:tc1} and~\ref{alg:tvg:tc2}) must have already happened. Therefore the algorithm terminates.

\section{Variable Abstraction}
\label{sec:variable_abstraction}

We now apply the three valued abstraction-refinement scheme to symbolic games (Section~\ref{sec:symbolic_games}). We describe an efficient instantiation of the three valued abstraction-refinement scheme for variable abstraction, a technique for reducing the state space of symbolic games by eliminating a subset of the state variables.

The description of three valued abstraction refinement leaves a lot unspecified. In particular

\begin{itemize}
    \item How is the initial abstraction specified?
    \item How are the controllable predecessors computed?
    \item How is the abstraction refined?
\end{itemize}

For clarity, I have created a running example in pseudocode which I will refer to throughout the description of the symbolic algorithm. The example is given in figure~\ref{fig:running_example}. The state variables are declared in the first section, followed by the label variables. Next, expressions for the goal and initial states are given. Finally, the state transitions are specified. For simplicity, all states in this game are controlled by player~1. Each action that player~1 may play updates a state variable. Note that the action chosen by player~1 is implicitly given by a label variable that player~1 may choose which takes one of the values in $\{a_1, a_2, a_3, a_4\}$. We denote this variable the $tag$.

\begin{figure}
\begin{lstlisting}[mathescape]

State vars:
X : Boolean;
Y : Boolean;
U : Boolean;
V : Boolean;

Label vars:
L : Boolean;

Goal: X==True $\wedge$ Y==True
Init: X==False $\wedge$ Y==False

Actions:
a1: X := True;
a2: Y := U;
a3: U := L;
a3: V := True;

\end{lstlisting}
\caption{The game specification for our running example}
\label{fig:running_example}
\end{figure}

\subsection{Variable Abstraction}

In variable abstraction, the abstract state space is created by dropping a subset of the state variables. The abstraction, $\alpha$, is defined by the state variables that remain. We denote this set $V_{\alpha}$.

Given the set $V_{\alpha}$, the corresponding abstraction (see Section~\ref{sec:abstraction_def}) is $\langle V, \concrete{} \rangle$, where:
\begin{itemize}
    \item $V$, the abstract state space, is the Cartesian product of the domains of the variables in $V_{\alpha}$.
    \item $\concrete{a}$ is the set of concrete states for which the variables in $V_{\alpha}$ take the same values in both the concrete state and $a$ and all other variables are free to take any value.
\end{itemize}

This abstraction satisfies our two requirements for a valid abstraction (Section~\ref{sec:abstraction_def}). 

\subsection{Initial abstraction}

The initial abstraction, $V_{init}$, for a boolean reachability game is created from only the variables that are mentioned in the goal. This ensures that the initial abstraction is \emph{precise} for the goal set.

The initial abstraction of our running example is illustrated in figure~\ref{fig:abs_state_sp}. $V_{init} = \{X, Y\}$. The abstract states are illustrated by the solid squares. There is one state for each valuation of $X$ and $Y$, the variables that occur in the goal in our example. Each abstract state contains four concrete states, one for each valuation of the concrete variables that were dropped from the abstraction, $U$ and $V$. $\concrete{}$ is a function from valuations of $U$ and $V$ to the powerset of the set of valuations of all state variables. For example:

\begin{equation}
    \concrete{\langle T, T \rangle} = \{ \langle T, T, F, F \rangle, \langle T, T, F, T \rangle, \langle T, T, T, F \rangle, \langle T, T, T, T \rangle \}
\end{equation}

Where the variables in each concrete tuple are ordered $\langle X, Y, U, V \rangle$. Note that $X$ and $Y$ are both True in all concrete state tuples whereas $U$ and $V$ are free to take any value.

It is clear from the figure that the abstraction forms a partition of the concrete state space and that it covers the entire concrete state space.

\begin{figure}[t]
\centering
\includegraphics[width=0.5\linewidth]{diagrams/statespace.pdf}
\caption{Abstract state space}
\label{fig:abs_state_sp}
\end{figure}

\subsection{Controllable predecessor}

The controllable predecessor is constructed using the transition relation. For efficiency, the transition relation will be constructed incrementally. As the state variables in our initial abstraction are only the variables in $G$, these are the only ones we need to compute the transition relation for initially.

Assuming that the transition relation for the concrete system is given as update functions, one for each concrete variable, then computation of the abstract transition relation $\delta$ is straightforward. We just compile the update functions for only those variables that appear in $G$ and take their conjunction.

However, there is the complication that these update functions may depend on additional variables that are not in $G$. Consider the update function for $Y$ in the running example. The next state value of $Y$ depends on $U$ which is not part of the abstract state space.

To handle this, we introduce an additional set of variables, denoted $F$ (for \emph{free}, for reasons that will become apparent) for variables that are needed when computing the update functions but are not part of the abstract state space. In our running example, at this stage, $F=\{U\}$.

Additionally, these update functions may depend on a subset of the label variables. In our running example, it is possible to set $U$ to the value of $L$, a label variable, and, each variable also implicitly depends on the $tag$ variable. These Boolean label variables that the update functions for state variables in $V_\alpha$ depend on are denoted $\Lambda$. Note that in our running example $U \notin V_\alpha$ initially, so initially $\Lambda$ is just $\{tag\}$.

We define the two controllable predecessors:

\begin{equation}
    \label{eqn:symb_cpre_M}
    Cpre_1^M(X) = \forall F. \exists \Lambda. \forall V_\alpha'. \delta \rightarrow X'
\end{equation}

\begin{equation}
    \label{eqn:symb_cpre_m}
    Cpre_1^m(X) = \exists F. \exists \Lambda. \forall V_\alpha'. \delta \rightarrow X'
\end{equation}

\noindent where $V_\alpha'$ is the next state copy of $V_\alpha$ and $X'$ is $X$ with all variables in $V_\alpha$ renamed to the corresponding variable in $V_\alpha'$.

Though the $F$ variables are really part of the state, we treat them as free input variables. Intuitively, their values are chosen by player~2 when computing $Cpre_1^M$ and by player~1 when computing $Cpre_1^m$. This makes it more difficult, and respectively, easier for player~1 to control execution into the target set.

Given a valuation of a subset of the concrete state variables $V \subseteq C$ we say that the valuation \emph{agrees} with a concrete state $c$ if the value assigned to each of the variables in $V$ equals the value assigned to the same variable by $c$. A subset of concrete state variables defines a partitioning of the concrete state space: 

\begin{equation}
    \{ s \in 2^C | \exists v \in Valuations(V). \forall c \in s. \text{ $c$ agrees with $v$} \}
\end{equation}

\begin{figure}
\centering
\includegraphics[width=0.5\linewidth]{diagrams/partitioning.pdf}
\caption{Partitioning induced by $\{U, X, Y\}$}
\label{fig:f_partitioning}
\end{figure}

We refer to each set of states in the partitioning as a \emph{sub-state}. Figure~\ref{fig:f_partitioning} shows the partitioning induced by $F=\{U\} \cup V_{init}=\{X, Y\}$ in our running example.

$Cpre_1^M$, by Equation~\ref{eqn:symb_cpre_M}, is the set of abstract states from which we can force execution into the target set from all sub-states induced by $F$. Since no variables in $C \setminus (V \cup F)$ can influence the next state of variables in $V$ \emph{we can ignore them} and conclude that $Cpre_1^M$ computes the set of abstract states such that for all concrete states within the abstract state, player~1 can force execution into the concretisation of the target set. This agrees with the definition of the abstract must controllable predecessor in Equation~\ref{eqn:def_cpre_M}.

Dually, $Cpre_1^m$ computes the set of abstract states such that for some concrete state within the abstract state, player~1 can force execution into the concretisation of the target set. This agrees with the definition of the abstract may controllable predecessor in Equation~\ref{eqn:def_cpre_m}.

In our running example our goal is $\langle X=True \land Y=True \rangle$. Consider the state $s = \langle X=True, Y=False \rangle$. $Y$ may be set to the value of $U$ by action $a_2$. As $U \in F$, it may be chosen by player~1 when computing $Cpre_1^m$. Player~1 may choose it to be $True$ and thus $s \in Cpre_1^m(goal)$. However, when computing $Cpre_1^M$, the environment gets to choose $U$ and it may choose $U=False$, and thus $s \notin Cpre_1^M(goal)$.

\subsection{Solving the game}

Now that we have an abstraction and a definition of the controllable predecessor we can solve the game. We first solve the game using $Cpre_1^M$ and denote the winning region $W^M$, or the \emph{must} winning region. We also solve the game using $Cpre_1^m$ and denote the winning region $W^m$ or the \emph{may} winning region.

Since $W^M$ is a subset of the true winning region, if $I \rightarrow W^M$ then we may terminate as the game is surely winnable. As $W^m$ is a superset of the true winning region, if $I \centernot\rightarrow W^m$ then we may terminate as the game is surely not winnable.

If none of the above termination conditions held then it is because our abstraction is not precise enough and must be refined.

The may (light gray) and must (dark gray) winning regions of our example system are given in figure~\ref{fig:may_must_win}. All states are may winning, but the top states are not must winning. These are the states where $Y$ is not $True$, as prescribed by the goal expression. Intuitively, this is because $U$ is not part of the abstraction. The solving algorithm is aware that the value of $Y$ can be set to the value of $U$ but it is not aware that $U$ can be set to $True$ by action $a2$.

After solving, the initial state is not classified as either losing or must winning. In the next section, we attempt to refine the abstraction to remove the imprecision that prevented us from definitively classifying the initial state. 

\begin{figure}[t]
\centering
\includegraphics[width=0.5\linewidth]{diagrams/solved.pdf}
\caption{May and must winning regions}
\label{fig:may_must_win}
\end{figure}

\subsection{Refinement}

\begin{algorithm}

\caption{Pseudocode of \textsc{refineAbstraction}}
\label{alg:refineAbstractionVar}

\begin{algorithmic}[1]
\Function{refineAbstraction}{$W^M$}
    \State $U^M \gets CpreU_1^M(W^M) \land \overline{W^M}$
    \State $toPromote \gets \vec{\omega}~\cap~$\Call{support}{\textsc{shortPrime}($U^M$)} \label{a:ra:extract_prime}
    \State $\Call{promote}{toPromote}$ \label{a:ra:promote}
\EndFunction
\end{algorithmic}
\end{algorithm}

The algorithm for refining the abstraction is given in Algorithm~\ref{alg:refineAbstractionVar}. As explained in Section~\ref{sec:threeval_generic}, when refining the abstraction of a reachability game, we can limit our search for states to split to the \emph{may-must boundary}. We split an abstract state in two such that from one of the new states $a$ it is possible to force execution into $W^M$ from every state in $\concrete{a}$. Instead of searching each state at the boundary in turn for a candidate state to split as was implied in section~\ref{sec:threeval_generic}, we find a candidate state using an efficient symbolic calculation.

We define the function $Cpre_1^F$ that returns the set of sub-states in the partition induced by the variables in $V_{\alpha} \cup F$ that are winning:

\begin{equation}
    Cpre_1^F(X) = \exists \Lambda. \forall V_\alpha'. \delta \rightarrow X'
\end{equation}

Note that this differs from Equations~\ref{eqn:symb_cpre_M} and~\ref{eqn:symb_cpre_m} in that it never quantifies out $F$. 

We compute:

\begin{equation}
    CPre_1^F(W^M) \wedge \neg W^M
    \label{eqn:edge}
\end{equation}

\noindent to find the sub-states that are not must winning but have a transition to the must winning set. This is the characteristic formula of the sub-states on the may-must boundary that are winning and are thus are part of a candidate state for splitting.

$Cpre_1^F(W^M)$ for our running example is illustrated as the dark states in Figure~\ref{fig:var_refinement}. The sub-states in the top half satisfy Equation~\ref{eqn:edge}.

We extract a large prime implicant from this characteristic function in line~\ref{a:ra:extract_prime}, an efficient operation with BDDs. We also extract the variables that occur in this prime that are not in $V_\alpha$ and call them $V_{pi} \subseteq F$. 

Notice that if we add the variables in $V_{pi}$ to $V_\alpha$, the abstraction induced by $V_\alpha$ is now precise enough to exactly represent the states in the implicant. These states are winning. This means that if we iterate the controllable predecessor one more time, we will at least discover that this implicant is winning, in addition to $W^M$. Thus, our refinement has grown the must winning set. In practice, refining the abstraction in this way usually discovers many more winning states than just the implicant. We call adding a variable to $V_\alpha$ \emph{promoting} the variable. We promote each variable in $V_{pi}$ on line~\ref{a:ra:promote}.

Returning to our example, one implicant of Equation~\ref{eqn:edge} is $\{X=1, Y=0, U=1\}$. $V_{pi}$ for this implicant is $\{U\}$. If we add $U$ to $V_\alpha$ we arrive at an abstraction that allows us to classify the initial state as must winning next time the game is solved. Thus, the game is winning. Notice that this algorithm allowed us to determine the game outcome without adding the variable $V$ to the abstraction. 

\begin{figure}[t]
\centering
\includegraphics[width=0.5\linewidth]{diagrams/refinement.pdf}
\caption{Refinement for variable abstraction}
\label{fig:var_refinement}
\end{figure}

\subsection{Putting it together}
The three valued variable abstraction refinement algorithm is given in Algorithm~\ref{alg:three_val_abs_ref}.

\begin{algorithm}
\caption{Three-valued abstraction refinement algorithm}
\label{alg:three_val_abs_ref}

\begin{algorithmic}[1]

\Require A game structure $G = \langle S, L, I, \tau_1, \tau_2, \delta \rangle$, a set 
of target states $T\subseteq S$, and an initial abstraction $\alpha=\langle V, \concrete{} \rangle$
that is precise for $T$, $I$, and $\tau_i$.

\Ensure {\it Yes} if $I \subseteq \reach(T, Cpre_1)$, and {\it No} otherwise.

\Function{Solve}{$transitionRelation$, $goal$}

    \Loop
        \State $W^M \gets \reach(\abstractM{T}, Cpre_1^M)$
        \State $W^m \gets \reach(\abstractm{T}, Cpre_1^m)$
        \If{$\abstractM{I} \subseteq W^M$} 
            \State\Return Yes
        \ElsIf{$\abstractM{I} \nsubseteq W^m$} 
            \State\Return No
        \Else       
            \State$\Call{refineAbstraction}{W^M}$
        \EndIf
    \EndLoop
\EndFunction

\end{algorithmic}
\end{algorithm}

\subsection{Optimisation}

There are two straightforward optimisations we can perform to speed up the abstraction refinement loop. The first is critical in practice as it drastically improves the performance of the algorithm.

\subsubsection{Reuse $W^M$ from the last abstraction-refinement iteration}

$W^M$ is, by definition, the set of states from which we know we can win with the current abstraction. If we refine the abstraction, this set can only grow, so it must at least include $W^M$ from the last iteration. This means that, after refinement when we solve the game again, we may begin iterating the controllable predecessor from the previously found $W^M$. This effectively saves us from having to discover again that this set is winning with the new abstraction. The modified algorithm is given in algorithm~\ref{alg:three_val_reach_reuse}.

\begin{algorithm}
\caption{Three-valued abstraction algorithm optimised to reuse previously discovered winning regions.}
\label{alg:three_val_reach_reuse}

\begin{algorithmic}[1]

\Require A game structure $G = \langle S, L, I, \tau_1, \tau_2, \delta \rangle$, a set 
of target states $T\subseteq S$, and an initial abstraction $\alpha=\langle V, \concrete{} \rangle$
that is precise for $T$, $I$, and $\tau_i$.

\Ensure {\it Yes} if $I \subseteq \reach(T, Cpre_1)$, and {\it No} otherwise.

\Function{Solve}{$transitionRelation$, $goal$}

    \State $W^M \gets \emptyset$

    \Loop
        \State $W^M \gets \reach(\abstractM{T} \vee W^M, Cpre_1^M)$
        \State $W^m \gets \reach(\abstractm{T} \vee W^M, Cpre_1^m)$
        \If{$\abstractM{I} \subseteq W^M$} 
            \State\Return Yes
        \ElsIf{$\abstractM{I} \nsubseteq W^m$} 
            \State\Return No
        \Else       
            \State$\Call{refineAbstraction}{W^M}$
        \EndIf
    \EndLoop
\EndFunction

\end{algorithmic}
\end{algorithm}

\subsubsection{Do not compute $W^m$}

If we expect the game to be winning, and we are only interested in solving the game to compute the strategy, we may avoid computing $W^m$ entirely. The purpose of computing $W^m$ is to terminate early if our abstraction is precise enough to determine that we cannot win. If we already know that we can win or we expect it is likely that we can win, then it is not worth computing. The modified algorithm is given in algorithm~\ref{alg:opt_three_val_reach}. It terminates when it discovers that the game is winning or when it finds that there are no refinements that guarantee that a new winning state will be found. The second termination condition happens when we were wrong and, in fact, the game was not winning. If we had computed a may winning set in addition, we would have discovered this much earlier so this algorithm is not a good choice when there is a reasonable possibility that the game is not winning.

\begin{algorithm}
\caption{Three-valued abstraction refinement for games optimised to not compute $W^m$}
\label{alg:opt_three_val_reach}

\begin{algorithmic}[1]

\Require A game structure $G = \langle S, L, I, \tau_1, \tau_2, \delta \rangle$, a set 
of target states $T\subseteq S$, and an initial abstraction $\alpha=\langle V, \concrete{} \rangle$
that is precise for $T$, $I$, and $\tau_i$.

\Ensure {\it Yes} if $I \subseteq \reach(T, Cpre_1)$, and {\it No} otherwise.

\Function{Solve}{$transitionRelation$, $goal$}

    \Loop
        \State $W^M \gets \reach(\abstractM{T}, Cpre_1^M)$
        \If{$\abstractM{I} \subseteq W^M$} 
            \State\Return Yes
        \Else       
            \State $res \gets \Call{refineAbstraction}{W^M}$
            \If{$res == False$}
                \State\Return No
            \EndIf
        \EndIf
    \EndLoop
\EndFunction

\end{algorithmic}
\end{algorithm}

\subsection{Summary}

In summary, the abstraction-refinement algorithm described in this section is very efficient because:
\begin{itemize}
    \item The algorithm reuses the winning sets computed earlier when the abstraction was simpler. This allows it to avoid the costly re-classification of these states again when the game is solved with a more complex abstraction.
    \item The transition relation is compiled incrementally on demand and kept partitioned. 
\end{itemize}

\subsection{Safety games}

Safety games are solved dually to reachability games and are given here for completeness. The algorithm is given in algorithm~\ref{alg:three_val_safe}. Note that \textsc{refineAbstraction} (Algorithm~\ref{alg:refineAbstractionSafe}) differs from the reachability game version as for safety games it is necessary to refine at the may-lose boundary (\cite{Alfaro_Roy_07}).

\begin{algorithm}
\caption{Three-valued abstraction refinement for safety games.}
\label{alg:three_val_safe}

\begin{algorithmic}[1]

\Require A game structure $G = \langle S, L, I, \tau_1, \tau_2, \delta \rangle$, a set 
of target states $T\subseteq S$, and an initial abstraction $\alpha=\langle V, \concrete{} \rangle$
that is precise for $T$, $I$, and $\tau_i$.

\Ensure {\it Yes} if $I \subseteq \safe(T, Cpre_1)$, and {\it No} otherwise.

\Function{Solve}{$transitionRelation$, $goal$}
    \State $W^M \gets \emptyset$

    \Loop
        \State $W^M \gets \safe(\abstractM{T} \wedge W^m, Cpre_1^M)$
        \State $W^m \gets \safe(\abstractm{T} \wedge W^m, Cpre_1^m)$
        \If{$\abstractM{I} \subseteq W^M$} 
            \State\Return Yes
        \ElsIf{$\abstractM{I} \nsubseteq W^m$} 
            \State\Return No
        \Else       
            \State$\Call{refineAbstraction}{W^m}$
        \EndIf
    \EndLoop
\EndFunction

\end{algorithmic}
\end{algorithm}

\begin{algorithm}

\caption{Pseudocode of \textsc{refineAbstraction for safety games}}
\label{alg:refineAbstractionSafe}

\begin{algorithmic}[1]
\Function{refineAbstraction}{$W^m$}
\State $U^m \gets \overline{CpreU_1^{m}(W^m)} \land W^m$
    \State $toPromote \gets \vec{\omega}~\cap~$\Call{support}{\textsc{shortPrime}($U^m$)}
    \State $\Call{promote}{toPromote}$
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Arbitrary $\omega$-regular games}
\label{sec:omega_reg}

We generalise the algorithm to games specified by $\mu$-calculus formulas in prefix normal form, ie, formulas of the form:

\begin{equation}
\nu X. \mu Y. \ldots \phi(X, Y, \ldots)
\end{equation}

or

\begin{equation}
\mu X. \nu Y. \ldots \phi(X, Y, \ldots)
\end{equation}

\noindent where the fixed point quantifiers strictly alternate. The algorithm is given in Algorithm~\ref{alg:generic_mu_calc}.

\begin{algorithm}
\caption{Three-valued abstraction refinement for $\mu$-calculus games}
\label{alg:generic_mu_calc}

\begin{algorithmic}[1]

\Require {\bf Input:} A game structure $G = \langle S, L, I, \tau_1, \tau_2, \delta \rangle$, a specification formula in prefix normal form $\phi$, and an initial abstraction $\alpha=\langle V, \concrete{} \rangle$ that is precise for each set that occurs in $\phi$, $I$, and $\tau_i$.

\Ensure {\bf Output:} {\it Yes} if $I \subseteq \textsc{Win}(\phi, Cpre_1)$, and {\it No} otherwise.

 \Function{Solve}{$transitionRelation$, $goal$}
    \Loop
    \State $W^M \gets \textsc{Solve}(\phi, Cpre_1^M)$ \label{a:tvmc:sM}
    \State $W^m \gets \textsc{Solve}(\phi, Cpre_1^m)$ \label{a:tvmc:sm}
        \If{$\abstractM{I} \subseteq W^M$} 
            \State\Return Yes \label{a:tvmc:Y}
        \ElsIf{$\abstractM{I} \nsubseteq W^m$} 
            \State\Return No \label{a:tvmc:N}
        \Else       
            \State$\Call{refineAbstraction}{W^M}$
        \EndIf
    \EndLoop
\EndFunction

\end{algorithmic}
\end{algorithm}

\begin{algorithm}

\caption{Pseudocode of \textsc{refineAbstraction} for $\mu$-calculus games}
\label{alg:refineAbstraction}

\begin{algorithmic}[1]
\Function{refineAbstraction}{$\phi$}

    \If{$\phi = \nu X. \psi$}

        \State $W^m \gets \textsc{Solve}(\phi, Cpre_1^m)$

        \State $U^m \gets \overline{CpreU_1^{m}(W^m)} \land W^m$
        \If{$U^m \neq False$}
            \State $toPromote \gets \vec{\omega}~\cap~$\Call{support}{\textsc{shortPrime}($U^m$)}
            \State $\Call{promote}{toPromote}$
        \Else
            \State \Call{refineAbstraction}{$\psi [X = W^m]$}
        \EndIf

    \ElsIf{$\phi = \mu X. \psi$}

        \State $W^M \gets \textsc{Solve}(\phi, Cpre_1^M)$

        \State $U^M \gets CpreU_1^{M-}(W^M) \land \overline{W^M}$
        \If{$U^m \neq False$}
            \State $toPromote \gets \vec{\omega}~\cap~$\Call{support}{\textsc{shortPrime}($U^M$)}
            \State $\Call{promote}{toPromote}$
        \Else
            \State \Call{refineAbstraction}{$\psi [X = W^M]$}
        \EndIf

    \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

The algorithm begins in the same way as for safety and reachability. We solve the game with the current abstraction to find $W^m$ and $W^M$ on lines~\ref{a:tvmc:sM} and~\ref{a:tvmc:sm} and terminate if these allow us to determine the outcome on lines~\ref{a:tvmc:Y} and~\ref{a:tvmc:N}. We then refine and solve again. Again, as in the reachability and safety cases, we aim to grow $W^M$ and shrink $W^m$ so that, if we do not terminate early, they will eventually become the same set. This guarantees termination through one of the if conditions. Predicate promotion is the same as before but operates on different boundary states. We describe the algorithm to find these boundaries. 

\subsubsection{Correctness}

Assuming correctness of the $Solve$ function, $W^m$ and $W^M$ will always contain an underapproximation, and overapproximation of the true winning region respectively. The algorithm only terminates through one of the if conditions on lines~\ref{a:tvmc:Y} and~\ref{a:tvmc:N}. If it terminates through the first one, then the initial state is a subset of $W^M$ and thus certainly a subset of the true winning region, so the algorithm correctly returns $Yes$. If it terminates through the second if condition, then the initial set is not a subset of $W^m$ and thus is certainly not a subset of the true winning region, so the algorithm correctly returns $No$. Thus the algorithm returns the correct answer at all termination conditions.

\subsubsection{Termination}

Suppose the specification formula is of the form $\nu X. \psi$, ie.\ it has a greatest fixed point at its outermost level. We have already calculated the may winning region and we denote this $X^m$ as it is the final value that the $X$ variable takes when solving the may game. We attempt to directly shrink $X^m$ by reconsidering the last application of $Cpre^m$ that yielded $X^m$ and looking for refinements that cause some of the may winning states found by this last iteration to become losing. This amounts to checking the $X^m$-lose boundary for additional losing states, in the same way safety games are refined, which also happens to be specified with a greatest fixed point.

We redo the last $CPre$ application as follows. We evaluate $\phi(X, Y, Z, \ldots)$ with each fixed-point-quantifier variable substituted as $X^m$, ie.\ $X=X^m$, $Y=X^m$, \ldots \ as these are the values that the fixed point variables had in the last iteration when the game was solved. This happens because the $mu$-calculus formula is in prefix normal form. We then use this value as the target and refine states and consistency relations as described previously. We re-solve if we succeed.

Making refinements only as described above does not guarantee that eventually $W^m = W^M$. We refine recursively as follows. We define a new objective: $\mu Y., \ldots, cpre(\phi(X=X^m, Y, \ldots))$, ie.\ we drop the $\nu X.$ quantifier and replace $X$ by $X^m$ and refine recursively with this. Note that $Y^m \neq Y^M$ as otherwise $X^m$ would equal $X^M$ and we would have terminated. Conceptually, we are trying to either grow $Y^M$ to $X^m$ ($=Y^m$) through repeated refinement, proving that $X^M = X^m$ (and terminating with an answer somewhere along the way), or find a reason why $Y^M$ does not equal $X^m$ (finding this is equivalent to shrinking $Y^m$, and hence $X^m$) and continue, having achieved our goal of bringing $X^m$ closer to $X^M$. One of the two outcomes (growing $Y^M$ to $X^m$ or shrinking $Y^m = X^m$) must happen because they are not equal initially and (by structural induction on the $mu$-calculus formula, assuming the algorithm is correct for shorter formulas, with safety and reachability as the base cases) must meet somewhere in the middle.

Note, that any refinements found in some step would have been found in a subsequent step had that step been skipped. We find that giving priority to the outermost fixed point results in better abstractions and as refinements for outer fixed points are cheaper to compute it makes sense to prioritise them.

Every recursive call drops one fixed point quantifier, so eventually we reach a formula of the form $Q X. \phi(X)$ where $X$ is either $\mu$ or $\nu$ and proceed as in the safety or reachability case. Termination is guaranteed for these, and, by induction for the rest of the specification.

\subsection{GR(1) games}

GR(1) games are a specific case of the above where the formula is:

\begin{equation}
    \nu X. \mu Y. \nu Z. Cpre((U \wedge Z) \vee (G \wedge X) \vee Y)
\end{equation}

Thus, the variable abstraction algorithm is correct and terminates for GR(1) games.

\section{Predicate abstraction}

Predicate abstraction has proved to be a particularly successful technique in model checking~\cite{Graf_Saidi_97}. Predicate abstraction partitions the state space of the game based on a set of predicates, which capture essential properties of the system. States inside a partition are indistinguishable to the abstraction, which limits the maximal precision of solving the game achievable within the given abstraction but greatly improves the scalability of the synthesis algorithm. As with variable abstraction, if the abstraction is too coarse, it is iteratively refined by introducing new predicates.

The key difficulty in applying predicate abstraction to games is to efficiently solve the abstract game arising at every iteration of the abstraction refinement loop. This requires computing the abstract \emph{controllable predecessor} operator efficiently. This involves enumerating concrete moves available to both players in each abstract state, which can be prohibitively expensive.  

We address the problem by further approximating the expensive controllable predecessor computation and refining the approximation when necessary. To this end, we introduce additional predicates that partition the set of actions available to the players into \emph{abstract actions}. The controllable predecessor computation then consists of two steps: 

\begin{enumerate}
    \item computing abstract actions available in each abstract state
    \item and, evaluating controllable predecessor over abstract states and actions
\end{enumerate}

The first step involves potentially expensive analysis of concrete transitions of the system and is therefore computed approximately. More specifically, solving the abstract game requires overapproximating moves available to one of the players, while underapproximating moves available to the other~\cite{Henzinger_JM_03}.  The former is achieved by allowing an abstract action in an abstract state if it is available in at least one corresponding concrete state, the latter allows an action only if it is available in all corresponding concrete states. We compute the overapproximation by initially allowing all actions in all states and gradually refining the abstraction by eliminating spurious actions.  Conversely, we start with an empty underapproximation and add available actions as necessary.

We build on the three valued variable abstraction-refinement scheme already developed. 

\subsection{Running Example}

We introduce our running example, where we aim to synthesise a driver for an artificially trivial I/O device. This example also motivates the need for predicate abstraction when synthesizing device drivers. The device contains $32$ bits of non-volatile memory, which can be accessed from software via the data register. The task of the driver is to transfer a data value from the main memory to the device memory.

We set up a game between the driver (player~1) and the device (player~2).  Device and driver internal state is modelled using state variables (Figure~\ref{fig:ex_game_variables}).  The player who makes the next move is determined by the value of the $bsy$ flag inside the device.  When the flag is set to $0$, the device remains idle and the driver may perform an action, such as a write to the data register.  When the flag is set to $1$, the device is performing an internal operation and no actions of the driver will have any effect. 

The argument of the write is modelled by the $val$ label variable. When the $write\_en$ label variable is set to true and the $bsy$ flag is false, a write operation happens on the next transition. The write operation flips the $bsy$ flag to $1$.  This triggers a device transition at the next round of the game, when it is player~2's turn, which copies the value in the data register to memory.  The objective of the game on behalf of player~1 is to reach the target set $T=(req=mem)$, i.e., the device memory must store the requested value $req$ (Figure~\ref{fig:ex_game_specification}).  We require that the game is winnable from any state, hence $I=\top$.  

The winning strategy for player~1 in this example is to write the value of $req$ in the first transition (by setting $val=req$), thus forcing the device to copy this value to memory at the second transition.

Figure~\ref{fig:ex_game_specification} specifies the transition relation $\delta$ of the game in the form of variable update functions $x' = t_x(X,Y)$, one for each variable $x\in X$.  Consider the update function for $bsy$ as an example.  The variable switches to $true$ if the device is not currently busy and the driver requests a write by setting $write\_en$. It switches back to $false$ on the next transition when the memory write operation completes.

\begin{figure}
    \centering
    \caption{Game variables}
    \label{fig:ex_game_variables}
    \begin{tabular}{|p{0.13\linewidth}p{0.22\linewidth}p{0.45\linewidth}|}
        \hline
        {\bf Var} & {\bf Type} & {\bf Description} \\
        \hline\hline
        \multicolumn{3}{|c|}{State variables ($X$)} \\
        \hline
        $mem$ & $int32$ & Device memory           \\
        $dat$ & $int32$ & Data register           \\
        $bsy$ & $bool$  & Device busy bit         \\
        $req$ & $int32$ & Value to write to $mem$ \\
        \hline\hline
        \multicolumn{3}{|c|}{Label variables ($Y$)}    \\
        \hline
        $val$       & $int32$ & Value to write to $dat$ \\
        $write\_en$ & $bool$  & Perform a write on this transition \\
        \hline
    \end{tabular}
\end{figure}

\begin{figure}
    \centering
    \caption{Game specification}
    \label{fig:ex_game_specification}
    \begin{subfigure}{\linewidth}
    \caption{Turn functions, initial and target sets}
    $\tau_1=(bsy=false)~~\tau_2=(bsy=true)~~I=\top~~T=(req=mem)$
    \end{subfigure}

    \begin{subfigure}{\linewidth}
    \caption{Variable update functions}
    \begin{tabular}{|p{0.9\linewidth}|}
        \hline
        $
        \begin{aligned}
            &dat' = \begin{cases}
                        val, & \text{if } \neg bsy \wedge write\_en \\
                        dat, & \text{otherwise}
                    \end{cases}\\
            &bsy' = \begin{cases} 
                        true,   & \text{if } \neg bsy \wedge write\_en \\
                        false,  & \text{if } bsy \\
                    \end{cases}\\
            &mem' = \begin{cases}
                        dat, & \text{if } bsy \\
                        mem, & \text{otherwise}
                    \end{cases}\\
            &req' = req\\
        \end{aligned}
        $ \\
        \hline
    \end{tabular}
    \end{subfigure}

\end{figure}

\subsection{Definitions}

We instantiate the three-valued abstraction refinement scheme for predicate abstraction instead of simple boolean variables. Consider a symbolic game $G = \langle S, L, I, \tau_1, \tau_2, \delta \rangle$ defined over state variables $X$ and label variables $Y$. Let $\Sigma\subseteq\forms(X)$ be a finite set of boolean predicates over the state variables. We refer to $\Sigma$ as \emph{state predicates}. We introduce boolean variables $\vect{\sigma}=(\sigma_1\ldots\sigma_n)$ to represent values of predicates $\Sigma$. Given a boolean variable $\sigma$, $\|\sigma\|$ denotes its corresponding state or label predicate. $\|\vect{\sigma}\|$ denotes the vector of all state predicates in $\Sigma$.

The state space $V$ of the abstract game is defined as $V = \mathbb{B}^n$, where each abstract boolean state vector $v\in V$ represents a truth assignment of variables $\vect{\sigma}$. The concretisation function $\concrete{}$ from Section~\ref{sec:abstraction_def} can be expressed as: 

\begin{equation}
\concrete{v}=\bigwedge_{i=1..n}\|\sigma_i\|=v_i
\end{equation}

\noindent which maps an abstract state $v$ into the set of concrete states such that each predicate in $\Sigma$ evaluates to true or false depending on the value of the corresponding element of $v$.

\begin{ex}
    \everymath{\mathtt{\xdef\tmp{\fam\the\fam\relax}\aftergroup\tmp}}
    \everydisplay{\mathtt{\xdef\tmp{\fam\the\fam\relax}\aftergroup\tmp}}
    Consider an abstraction of the running example game induced by abstract variables $\sigma_1$, $\sigma_2$ and corresponding predicates: $\|\sigma_1\| = (req=dat)$, $\|\sigma_2\| = (req = mem)$.  Consider an abstract state $v=(true,false)$. We compute $\concrete{v} = ((req=dat) = true \land (req = mem)=false)$ or equivalently $\concrete{v} = (req=dat \land req \neq mem)$.  Hence $v$ represents the set of all concrete states where conditions $(req=dat)$ and  $(req \neq mem)$ hold for concrete state variables $mem$, $req$, and $dat$.
    \qed
\end{ex}

\begin{figure}
    \centering
    \caption{Abstract variables and corresponding predicates}
    \label{fig:ex_game_abstraction}
    \begin{tabular}{|p{0.14\linewidth}|p{0.5\linewidth}|}
        \hline
        {\bf a.var} & {\bf predicate} \\
        \hline\hline
        \multicolumn{2}{|c|}{state predicates} \\
        \hline
        $\sigma_1$ & $req=dat$   \\
        $\sigma_2$ & $req=mem$   \\
        \hline\hline
        \multicolumn{2}{|c|}{untracked predicates} \\
        \hline
        $\omega_1$ & $bsy=false$ \\
        $\omega_2$ & $req=5$     \\
        \hline\hline
        \multicolumn{2}{|c|}{label predicates} \\
        \hline
        $\lambda_1$ & $val=req$  \\
        $\lambda_2$ & $val=5$    \\
        \hline
    \end{tabular}
\end{figure}

\section{Approximate Three Valued Abstraction Refinement}

The goal of the following sections is to apply the machinery developed in the previous sections for variable abstraction to predicate abstraction. There are several pitfalls, so we must identify these pitfalls and take them into account.

\subsection{Motivation}
The abstraction-refinement scheme described in Section~\ref{sec:three_val_abs_ref} is very general. It makes the assumption that both of the controllable predecessors, $\cprem$ and $\cpreM$, can be computed precisely and efficiently.

While it was straightforward to compute them when performing variable abstraction on a boolean game, it is not clear that they can be computed efficiently when performing predicate abstraction.

\begin{ex}
    \everymath{\mathtt{\xdef\tmp{\fam\the\fam\relax}\aftergroup\tmp}}
    \everydisplay{\mathtt{\xdef\tmp{\fam\the\fam\relax}\aftergroup\tmp}}
    Consider the label abstraction induced by abstract label variables $\lambda_1$ and $\lambda_2$ and the corresponding label predicates $\|\lambda_1\| = (val=req)$ and $\|\lambda_2\| = (val=5)$.

    When performing variable abstraction, we would have treated $\lambda_1$ and $\lambda_2$ as independent variables. Each player was able to set them to any value in any state. However, when performing predicate abstraction, they are not independent, as they share the $val$ variable. Suppose player~1 tries to set them both to true. This can only be performed when $req=5$. This additional state predicate is needed to keep track of which label predicate combinations are valid.
    \qed
\end{ex}

This is just one of the potential pitfalls of handling predicate abstraction in the same way as variable abstraction. 

\subsection{Algorithm}

Following \cite{Alfaro_Roy_07}, we modify the general three valued abstraction-refinement algorithm to work on approximate versions of the controllable predecessor operators, $\cpremp$ and $\cpreMm :: 2^V \rightarrow 2^V$. In the following sections we will show how to efficiently compute these operators for predicate abstractions using techniques similar to variable abstraction. 

We lose precision when approximating the controllable predecessors, just as we do when approximating the state space with standard three valued abstraction-refinement. Thus, we need to introduce another form of refinement. This form of refinement refines the controllable predecessor operators themselves. This process is shown graphically in Figure~\ref{fig:approx_three_val_overview}. Conceptually, refining the controllable predecessors shrinks the gap between $\cpreM$ and $\cpreMm$ or the gap between $\cprem$ and $\cpremp$. We also perform refinement of the abstraction as before.

We require that, for all $U \subseteq V$ we have:

\begin{figure}
\centering
\includegraphics[width=0.85\linewidth]{imgs/approxThreeValue.pdf}
\caption{Overview of approximate three valued abstraction-refinement}
\label{fig:approx_three_val_overview}
\end{figure}


\begin{equation}
\label{eqn:cpre_p1}
\cprem \subseteq \cpremp
\end{equation}

\noindent and

\begin{equation}
\label{eqn:cpre_p2}
\cpreMm \subseteq \cpreM
\end{equation}

With these operators we create a new approximate abstraction-refinement scheme given in Algorithm~\ref{alg:approx_three_val}. Note that the algorithm relies on \textsc{refineCpre} and \textsc{refineAbstraction} which we will define for predicate abstraction in the following sections.

\begin{algorithm}
\caption{Approximate three-valued abstraction-refinement}
\label{alg:approx_three_val}

\begin{algorithmic}[1]

\Require {\bf Input:} A game structure $G = \langle S, L, I, \tau_1, \tau_2, \delta \rangle$, a set of target states $T\subseteq S$, and an initial abstraction $\alpha=\langle V, \concrete{}, Cpre_1^{m+}, Cpre_1^{M-} \rangle$ that is precise for $T$, $I$, and $\tau_i$.

\Ensure {\bf Output:} {\it Yes} if $I \subseteq \reach(T, Cpre_1)$, and {\it No} otherwise.

\Function{Solve}{$transitionRelation$, $goal$}
    \Loop
        \State $W^M \gets \reach(\abstractM{T}, Cpre_1^{M-})$
        \State $W^m \gets \reach(\abstractm{T}, Cpre_1^{m+})$
        \If{$\abstractM{I} \subseteq W^M$} \Return Yes \label{alg:atv:t1}
        \ElsIf{$\abstractM{I} \nsubseteq W^m$} \Return No \label{alg:atv:t2}
        \Else       
            \State $refined \gets \Call{refineCpre}{W^M}$
            \State \algorithmicif{} {$(\neg refined)$}
                $\Call{refineAbstraction}{W^M}$
            \algorithmicend \algorithmicif
        \EndIf
    \EndLoop
\EndFunction

\end{algorithmic}
\end{algorithm}

\section{Abstraction-Refinement for Predicate Abstraction}

The goal of the following sections is to create a symbolic version of algorithm~\ref{alg:approx_three_val} adapted to predicate abstraction.

\subsection{Abstract Transition Relations}
\label{s:cpre}

Following the three-valued abstraction-refinement algorithm presented in Section~\ref{sec:three_val_abs_ref}, we would like to find an efficient way to compute over- and under-approximations $Cpre^{m+}$ and $Cpre^{M-}$ of the abstract controllable predecessor operators. Recall that computing $Cpre^m$ and $Cpre^M$ precisely is expensive, as it requires applying the controllable predecessor operator to the concrete transition relation $\delta$. We approximate this costly computation by computing the controllable predecessor over the \emph{abstract transition relation} instead. The abstract transition relation of the game is defined over boolean predicate variables and therefore can be manipulated much more efficiently than the concrete one.

We construct the abstract transition relation via efficient syntactic analysis of the concrete transition relation $\delta$. We present the construction assuming that $\delta$ is given in the variable update form, as in Figure~\ref{fig:ex_game_specification}b. A similar construction is possible for specifications written in real-world hardware and software description languages.

For each state predicate in $\Sigma$, we compute the update function by replacing concrete variables in the predicate with their corresponding update functions. We then transform the resulting formula into a boolean combination of atomic predicates over concrete state and label variables.

In the general case, the syntactically computed update function for a predicate may depend on existing state predicates in $\Sigma$ as well as new predicates that are not yet part of the abstraction.  The new predicates are partitioned into \emph{untracked predicates} defined over concrete state variables (e.g., $\mathtt{bsy=false}$ in Figure!\ref{fig:ex_game_specification}a) and \emph{label predicates} that involve at least one concrete label variable (e.g., $\mathtt{val=req}$).  The term ``untracked predicate'' indicates that these predicates are not part of the abstract state space of the game.  Untracked predicates can be seen as partitioning abstract states in $V$ into smaller \emph{untracked sub-states}, as illustrated in Figure~\ref{f:crefinement}.

\begin{ex}
    Let us compute the update function for abstract variable $\sigma_1$ (Figure~\ref{fig:ex_game_abstraction}).  Using update functions for $req$ and $dat$ variables (Figure~\ref{fig:ex_game_variables}b), we obtain: 
    
    \begin{multline}
    \sigma_1' = (req' = dat') = \neg(bsy = false) \land (req=dat) \\ \lor (bsy=false) \land (val=req)
    \end{multline}
    
    \noindent This equation contains three atomic predicates: in addition to the existing predicate $\sigma_1 \leftrightarrow (req=dat)$, it introduces new predicates $(bsy=false)$ and $(val=req)$.  

    The first two predicates correspond to existing state variables $\sigma_1$ and $\sigma_2$.  The last predicate is new; hence it is added to set $\Omega$ and a new untracked variable $\omega_1$ is created for it.  By substituting predicates in the equation with corresponding abstract variables, we obtain the following abstract transition relation for $\sigma_1$ in line~11 of the algorithm:
    $\sigma_1' = (\overline{\sigma_2} \land \omega_1) \lor (\sigma_2 \land \sigma1)$
    \qed
\end{ex}

By substituting untracked and label predicates with fresh boolean variables, $\vect{\omega}$ and $\vect{\lambda}$ respectively, we obtain the abstract transition relation $\Delta$ in the form:

$$
\vect{\sigma}'=\Delta(\vect{\sigma},\vect{\omega},\vect{\lambda})
$$

This syntactically computed transition relation contains two sources of imprecision.  

\begin{itemize}
    \item First, untracked variables $\vect{\omega}$ are not part of the abstract state space $\Sigma$ and are therefore treated as external inputs.  
    \item Second, not all abstract labels  are available in all abstract states and hence not all transitions in $\Delta$ correspond to a feasible concrete transition.  For example, given the set of predicates shown in Figure~\ref{fig:ex_game_abstraction}, the abstract label $\lambda_1 = true, \lambda_2 = true$ is only available in concrete states that satisfy the condition $req=5$.  In general, given a state-untracked-label tuple $\langle v,u,l\rangle$, the abstract label $l$ may be available in all, some, or none of the concrete states consistent with $v$ and $u$.  
\end{itemize}

\subsection{Consistency Relations}

We formalise the second source of imprecision by introducing \emph{consistency relations} $C^m$ and $C^M$ that over- and under-approximate available abstract labels.  A state-untracked-label tuple $\langle v,u,l\rangle$ is \emph{may-consistent} if the abstract label $l$ is available in \emph{at least one} concrete state consistent with $v$ and $u$:

\begin{equation} 
    \label{eqn:cm}
    C^m(v,u,l) = \exists X,Y. \|\vect{\sigma}\|=v \land \|\vect{\omega}\|=u \land \|\vect{\lambda}\|=l.
\end{equation}

The tuple $\langle v,u,l\rangle$ is \emph{must-consistent} if $l$ is available in \emph{any} concrete state consistent with $v$ and $u$:

\begin{equation}
    \label{eqn:cM}
    C^M(v,u,l) = \forall X . ((\|\vect{\sigma}\|=v \land \|\vect{\omega}\|=u) \rightarrow \exists Y.  \|\vect{\lambda}\|=l)
\end{equation}

Computing $C^m$ and $C^M$ can be prohibitively expensive.  Therefore we use approximations $C^{m+}$ and $C^{M-}$ such that 

\begin{equation}
    C^m\subseteq C^{m+}
\end{equation}
and 
\begin{equation}
    C^{M-}\subseteq C^M
\end{equation} 

Initially we assign $C^{m+}=\top$ and $C^{M-}=\bot$.  Approximations are refined lazily as part of the abstraction refinement process, as explained below.

\begin{ex}
    \everymath{\mathtt{\xdef\tmp{\fam\the\fam\relax}\aftergroup\tmp}}
    \everydisplay{\mathtt{\xdef\tmp{\fam\the\fam\relax}\aftergroup\tmp}}
    To illustrate the above definitions, we introduce two label predicates to our running example: $\|\lambda_1\|= (val=req)$, $\|\lambda_2\| = (val=5)$. Consider the state-untracked-label tuple $v=(true,false)$, $u=(true)$, $l=(true, true)$, which corresponds to the following assignment to abstract variables: $\sigma_1=true \land \sigma_2=false \land \omega_1=true \land \lambda_1=true \land\lambda_2=true$. It is easy to see that this condition is satisfied for example by the following concrete variable valuation: $mem=5$, $dat=5$, $bsy=true$, $req=5$, $val=5$, hence $\langle v,u,l\rangle$ is may-consistent: $C^m(v,u,l)=true$.  However, it is not must-consistent:

    $$
    \begin{aligned}
        C^M(v,u,l) = \forall  mem, dat, bsy,req. (&((req=mem) \land (bsy = true) \land (req=dat)) \rightarrow \\
                                                  &\exists val. (val=req) \land (val=5))
    \end{aligned}
    $$
    
    There exist concrete state variable assignments (e.g., $mem=1$, $dat=1$, $bsy=true$, $req=1$) that satisfy state and untracked predicates in the left-hand side of the implication but that can not be extended with a label variable assignment that satisfies the right-hand side, hence $C^M(v,u,l)=false$.  
    \qed
\end{ex}

\subsection{Abstract Controllable Predecessor}

We compute over- and under-approximations of the controllable predecessor operator by resolving the two sources of imprecision in favour of one of the players.  In particular, we compute $Cpre_i^{m+}$ by (1) allowing player $i$ to pick assignments to untracked predicates, (2) over-approximating consistent labels available to $i$, and (3) under-approximating consistent labels available to the opponent player $\overline{i}$:

\begin{equation}
\label{e:cprem}
\begin{aligned}
    Cpre_i^{m+}(\phi) = \exists \vect{\omega} .~&\abstractM{\tau_i}         \land \exists \vect{\lambda},\vect{\sigma'}. ((C^{m+} \land \Delta) \land \phi')
                                                 ~~\lor\\
                                                &\abstractM{\tau_{\overline{i}}} \land \forall \vect{\lambda},\vect{\sigma'}. ((C^{M-} \land\Delta) \rightarrow \phi')
\end{aligned}
\end{equation}

This formula has a similar structure to the definition of the variable abstraction controllable predecessor operator (Equation~\ref{eqn:symb_cpre_m}).  It replaces the concrete transition relation $\delta$ with the abstract transition relation $\Delta$ restricted with consistency relations ($C^{m+}$ and $C^{M-}$).  In addition, it existentially quantifies untracked variables $\vect{\omega}$, i.e., an abstract state $v$ is a may-predecessor of $\phi$ if at least one of its untracked sub-states is a may-predecessor of $\phi$.

Dually, we compute $Cpre_i^{M-}$ by (1) allowing the opponent player $\overline{i}$ to pick values of untracked predicates, (2) under-approximating labels available to $i$ and (3) over-approximating labels available to $\overline{i}$:

\begin{equation}
\label{e:cpreM}
\begin{aligned}
    Cpre_i^{M-}(\phi) = \forall \vect{\omega}.~&\abstractM{\tau_i}         \land \exists \vect{\lambda},\vect{\sigma'}. ((C^{M-} \land \Delta) \land \phi')
                                             ~~\lor\\
                                               &\abstractM{\tau_{\overline{i}}} \land \forall \vect{\lambda},\vect{\sigma'}. ((C^{m+} \land \Delta) \rightarrow \phi')
\end{aligned}
\end{equation}

Note that the use of $C^{m+}$ and $C^{M-}$ in (Equation~\ref{e:cprem}) and (Equation~\ref{e:cpreM}) under-constrains moves available to player~$i$ and over-constrains moves available to the opponent.  

Equations~\ref{e:cprem} and~\ref{e:cpreM} suggest two possible abstraction refinement tactics, which correspond to the two types of refinement used in Algorithm~\ref{alg:generic}.  First, we can refine $C^{m+}$ and $C^{M-}$ by removing spurious transitions from $C^{m+}$ or adding new consistent transitions to $C^{M-}$.  Such a refinement increases the precision of controllable predecessor computation without introducing new state predicates, which corresponds to the \textsc{refineCpre} operation in the algorithm.  Second, we can add some of the untracked predicates to the set of state predicates $\Sigma$, thus reducing the imprecision introduced by treating them as external inputs.  This refinement increases the precision of the abstraction, which corresponds to the \textsc{refineAbstraction} function in the algorithm.

In summary, we solve the abstract game by decomposing potentially expensive computations into four types of light-weight operations performed on demand, as required to improve the precision of the abstraction:

\begin{itemize}
    \item Computing the abstract transition relation $\Delta$ via light-weight syntactic analysis of the concrete game
    \item Computing consistency relations $C^{m+}$ and $C^{M-}$ by iteratively identifying spurious and consistent transitions
    \item Iteratively refining the abstraction used in the syntactic computation of the transition relation
    \item Solving the abstract game using abstract controllable predecessor operators (Equation~\ref{e:cprem}) and (Equation~\ref{e:cpreM})
\end{itemize}

The computational bottleneck in this method can arise either from having to perform an excessive number of refinements or if abstractions generated by the algorithm are too complex.  Our refinement procedures, described below, are designed to avoid such situations by heuristically picking refinements that are likely to speed up the convergence of the algorithm.

%\subsection{Abstract transition relation}
%
%The \emph{abstract transition relation}
%$\Delta: \mathbb{B}^n \times \mathbb{B}^k \times \mathbb{B}^m 
%\rightarrow 2^{\mathbb{B}^n}$
%of the game maps an assignment of state, untracked, and label 
%predicates to the set of possible next states.  The arrow in 
%Figure~\ref{f:predicates} illustrates a transition from untracked 
%sub-state $u$ of state $v$ to state $v'$ via abstract label $l$.  
%Note that the source of an abstract transition is a pair of state 
%and untracked predicate assignments, while the target of the 
%transition is an assignment to state predicates only.
%
%Algorithm~\ref{alg:delta} shows the pseudocode of function 
%\textsc{Delta}.  It takes a list of state predicates and returns 
%the abstract transition relation $\Delta$ along with untracked and 
%label predicates used in $\Delta$.
%It assumes that the concrete transition relation $\delta$ of the 
%game is specified in the form of variable update functions $x' = 
%t_x(X,Y)$, as in Figure~\ref{f:ex}b.
%
%\begin{algorithm}[t]
%\caption{Pseudocode for computing the abstract transition relation.}
%\label{alg:delta}
%\begin{algorithmic}[1]
%    \Function{Delta}{$\vect{\sigma}=(\sigma_1\ldots\sigma_n)$ - state predicate variables}
%        \For{$i = 1 \text{ to } n$}
%            \State $t_{\sigma_i} \gets \|\sigma_i \|[x \mid t_x(X,Y), \text{for all } x\in X]$
%            \State $t_{\sigma_i} \gets $ \Call{massage}{$t_{\sigma_i}$}
%        \EndFor
%        \State $P \gets \bigcup_i \text{atomic predicates in }t_{\sigma_i}$
%        \State $\Omega \gets \text{state predicates in } P \setminus \Sigma$
%        \State $\Lambda \gets \text{label predicates in } P \setminus \Sigma$
%        \State $\vect{\omega}\gets \text{fresh variables for predicates in } \Omega$
%        \State $\vect{\lambda} \gets \text{fresh variables for predicates in } \Lambda$
%        \State $\Delta \gets \bigwedge_i (\sigma_i' = t_{\sigma_i}[\|\alpha\|\mid \alpha, \text{for all } \alpha\in\vect{\sigma}\cup\vect{\omega}\cup\vect{\lambda}])$
%        \State \Return $\langle \vect{\omega}, \vect{\lambda}, \Delta \rangle$
%    \EndFunction
%\end{algorithmic}
%\end{algorithm}
%
%Lines 2--5 of the algorithm compute update functions for predicate 
%variables $\sigma_i$ by replacing each variable $x$ in predicate 
%$\|\sigma_i\|$ by its update function $t_x$.  The \textsc{massage} 
%function transforms the resulting expression $t_{\sigma_i}$ into a 
%boolean combination of atomic predicates over $X \cup Y$.  In 
%line~6 we collect all predicates found in $t_{\sigma_i}$.  The 
%resulting set $P$ may contain predicates not found in $\Sigma$.  
%Such predicates are classified into untracked predicates $\Omega$ 
%defined over state variables only and label predicates $\Lambda$ 
%that involve at least one label variable from $Y$ (lines~7--8).  
%The abstract transition relation $\Delta$ is computed by replacing 
%all boolean predicates in $t_{\sigma_i}$ with corresponding 
%boolean variables (line~11).
%
%\begin{ex}
%    \everymath{\mathtt{\xdef\tmp{\fam\the\fam\relax}\aftergroup\tmp}}
%    \everydisplay{\mathtt{\xdef\tmp{\fam\the\fam\relax}\aftergroup\tmp}}
%    Let us compute the update function for abstract variable 
%    $\sigma_1$. Recall that $\|\sigma_1\| = (req=mem)$.  Using 
%    update functions for $req$ and $mem$ variables from 
%    Figure~\ref{f:ex}b, we obtain:
%    $t_{\sigma_1} = (t_{req}(X,Y)=t_{mem}(X,Y)) = \bigg(req = 
%    \begin{cases}
%        dat, & \text{if } \neg bsy\\
%        mem, & \text{otherwise}
%    \end{cases}\bigg).$  The \textsc{massage} function transforms 
%    this into:
%    $t_{\sigma_1} = \big((bsy = true \land req=dat) \lor 
%    (bsy=false \land req=mem)\big)$.
%    This equation contains three predicates: $(req=mem)$, 
%    $(bsy=false)$ (and its negation), and $(req=dat)$.  The first 
%    two predicates correspond to existing state variables 
%    $\sigma_1$ and $\sigma_2$.  The last predicate is new; hence 
%    it is added to set $\Omega$ and a new untracked variable 
%    $\omega_1$ is created for it.  By substituting predicates in 
%    the equation with corresponding abstract variables, we obtain 
%    the following abstract transition relation for $\sigma_1$ in 
%    line~11 of the
%    algorithm:
%    $\sigma_1' = (\overline{\sigma_2} \land \omega_1) \lor (\sigma_2 \land \sigma1)$
%    \qed
%\end{ex}
%
%The above algorithm has the useful property that $\Delta$ is 
%computed via simple syntactic transformations of the concrete 
%game specification. Additionally, untracked predicates discovered 
%by the algorithm are known to influence the values of state 
%predicates in $\Sigma$. As such, these predicates constitute 
%potentially useful candidates for promotion to state predicates 
%as part of the abstraction refinement process.

\subsection{Consistency Refinement}
\label{sec:cons_refinement}

Figure~\ref{f:crefinement} illustrates the main idea of the consistency refinement algorithm.  It shows an abstract state $v$ (Figure~\ref{f:crefinement}a) at the may-must boundary whose untracked substates $u_1$, $u_2$, and $u_3$ have $C^{m+}$-consistent transitions to the must-winning set $W^M$, but none of these transitions is consistent with $C^{M-}$.  The \textsc{refineCpre} algorithm attempts to precisely categorise these substates as must-winning or must-losing.

Since all untracked substates of $v$ are either must-losing or may-winning but not must-winning, it is impossible to split out a must-winning subset of $v$ purely by predicate promotion; hence a consistency refinement is needed.

The consistency refinement algorithm proceeds in one of three ways:
\begin{itemize}
    \item In Figure~\ref{f:crefinement}b, the algorithm identifies the abstract transition $\langle v,u_1, l_1\rangle$ as spurious and eliminates it from $C^{m+}$, thus making the $u_1$ sub-state must-losing.  
    \item Alternatively, it may detect that abstract transition $\langle v, u_2, l_2\rangle$ is available in all concrete states in $u_2$ and thus add this transition to $C^{M-}$, making the $u_2$ sub-state must-winning (Figure~\ref{f:crefinement}c).  
    \item Finally, it may determine that abstract transition $\langle v, u_3, l_3\rangle$ is available in some, but not all, concrete states in $u_3$, i.e., $\langle v, u_3, l_3\rangle\in C^m\setminus C^M$.  It then partitions $u_3$ into two or more subsets, exactly one of which has a $C^{M-}$-consistent transition to $W^M$, by introducing new untracked predicates (Figure~\ref{f:crefinement}d).  
\end{itemize}

In all three cases, further refinement via untracked predicate promotion becomes possible.  Such refinement is performed by the \textsc{refineAbstraction} function described in Section~\ref{sec:refineAbstraction}.

\begin{figure}[t]
    \center
    \includegraphics[width=\linewidth]{imgs/crefinement}
    \caption{Different types of consistency refinements.  White, grey, and black background is used to mark respectively must-losing, may-winning, and must-winning untracked substates.  Dashed and solid arrows show $C^{m+}$ and $C^{M-}$-consistent abstract transitions.}
    \label{f:crefinement}
\end{figure}

Note that in the special case when, after performing consistency refinement, all untracked substates of $v$ become must-winning or must-losing, the entire state $v$ can be removed from the boundary region without performing predicate promotion. 

For this reason, Algorithm~\ref{alg:generic} recomputes $W^M$ and $W^m$ after each successful consistency refinement, and only calls \textsc{refineAbstraction} once no more consistency refinements are possible.

\subsubsection{Consistency Refinement Algorithm}

Algorithm~\ref{alg:refineCpre} shows the pseudocode of \textsc{refineCpre}.  Lines~3--6 compute the set of candidate tuples $\langle v, u, l\rangle\in C^m\setminus C^M$.  Note that for player~$i$ states we consider may-consistent transition to $W^M$, whereas for player~$\overline{i}$ states we consider spoiling transitions to $V\setminus W^M$.

Line~9 picks a single refinement candidate $\langle v,u,l \rangle$ from the set.  By construction we know that $\langle v,u,l\rangle\in C^{m+}$.  Since $C^{m+}$ is an overapproximation of $C^m$, we check whether $\langle v,u,l\rangle\in C^m$, i.e., whether $v$, $u$, and $l$ satisfy Equation~\ref{eqn:cm}.  To this end, in line~11 we invoke a decision procedure for the underlying theory to check satisfiability of the formula:$(\|\vect{\sigma}\|=v \land \|\vect{\omega}\|=u \land \|\vect{\lambda}\|=l)$.If the formula is unsatisfiable, then $\langle v,u,l\rangle$ is a spurious transition that must be eliminated from $C^{m+}$.  Furthermore, by extracting an unsatisfiable core of the formula,we obtain an inconsistent subset of its conjuncts $(\bigwedge\|\alpha_i\|=c_i)$, $\alpha_i\in\vect{\sigma}\cup\vect{\omega}\cup\vect{\lambda}$,which represents a potentially large set of similar spurious transitions.  We eliminate all of these transitions from $C^{m+}$ inline~16.

\begin{algorithm}[t]

\caption{Pseudocode of the \textsc{refineCpre} function}
\label{alg:refineCpre}
\begin{algorithmic}[1]
\Function{refineCpre}{$W^M$}
    \State \Comment{player~$i$ may-winning transitions}
    \State $T_i         \gets \abstractM{\tau_i} \land C^{m+} 
    \land {\overline{C^{M-}}} \land \forall \vect{\sigma'}. (\Delta \rightarrow (W^M)')$
    \State \Comment{player~$\overline{i}$ may-spoiling transitions}
    \State $T_{\overline{i}} \gets \abstractM{\tau_{\overline{i}}} \land C^{m+} \land {\overline{C^{M-}}} \land \exists \vect{\sigma'}. (\Delta \land \overline{(W^M)'})$
    \State $T           \gets T_i \lor T_{\overline{i}}$
    \If{$T = \bot$}
        \Return $false$ \Comment{no refinement is possible}
    \Else
        \State choose $\langle v,u,l\rangle \in T$
        \State $F \gets (\|\vect{\sigma}\|=v \land \|\vect{\omega}\|=u \land \|\vect{\lambda}\|=l)$
        \If{\Call{satisfiable}{$F$}} \label{a:refineCpre:sat}
            \State $A             \gets $ \Call{eliminateQuantifiers}{$\exists Y.\|\vect{\lambda}\|=l$} \label{a:refineCpre:quant}
            \State $A             \gets $ \Call{massage}{$A$}
            \State $P             \gets \text{atomic predicates in }A$
            \State $\vect{\omega} \gets \vect{\omega} \cup (\text{fresh variables for predicates in } P\setminus\Omega)$
            \State $\Omega        \gets \Omega \cup P$
            \State $\hat{A}       \gets A[\|x\|\mid x, \text{for all } x\in\Omega \cup \Sigma ]$
            \State $\hat{A}       \gets$ replace atomic predicates in $A$ with boolean
            \Statex  ~~~~~~~~~~~~~~~~~~~~vars, introducing fresh vars when necessary
            \State $C^{M-}        \gets C^{M-} \lor (\hat{A}\land \vect{\lambda}=l)$% \Comment{add consistent transition}
        \Else
%            \State $(\bigwedge\|\alpha_i\|=c_i) \gets$ \Call{unsatCore}{$F$}
            \State $C^{m+}\gets C^{m+} \land \overline{\textsc{unsatCore}(F)}$ \label{a:refineCpre:core}%\Comment{eliminate spurious transitions} 
        \EndIf
        \State \Return $true$
    \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

If, on the other hand, the formula is satisfiable, then there exists a concrete state-label pair consistent with $\langle v,u,l\rangle$.  In this case we want to precisely characterise the set of states where label $l$ is available, so that we can either add $\langle v,u,l\rangle$ to $C^{M-}$ (as in Figure~\ref{f:crefinement}c) or refine it with additional untracked predicates (as in Figure~\ref{f:crefinement}d).

Line~12 computes the set of concrete states where abstract label $l$ is available by performing quantifier elimination from formula $(\exists Y.\|\vect{\lambda}\|=l)$, resulting in a quantifier-free formula $A$ over concrete state variables $X$.  We assume that the underlying theory supports quantifier elimination, which is the case for many practically relevant theories, including the theory of fixed-size bit vectors supported by our tool.  In line~13, the resulting formula $A$ is decomposed into atomic predicates possibly introducing new untracked and label predicates.  By replacing all atomic predicates in $A$ with corresponding boolean variables, we obtain a formula $\hat{A}$ that describes the set of all state-untracked pairs must-consistent with the abstract label $l$.  Line~14 refines $C^{M-}$ with the set of newly discovered must-consistent transitions.

%The resulting formula is decomposed into atomic predicates 
%(lines~11--12).  New predicates from $A$ are added to the set of 
%untracked predicates (lines~13--14).  Finally, all predicates in 
%$A$ are replaced with corresponding boolean variables (line~15) 
%and the resulting formula over abstract variables is used to 
%refine the must consistency relation $C^{M-}$ (line~16).  

\begin{ex}
    \everymath{\mathtt{\xdef\tmp{\fam\the\fam\relax}\aftergroup\tmp}}
    \everydisplay{\mathtt{\xdef\tmp{\fam\the\fam\relax}\aftergroup\tmp}}
    Assume that in line~9 the algorithm picks a tuple $\langle v,u,l\rangle$ where $l=(true, true)$.  Line~12 performs quantifier elimination from the formula $\exists val. (\|\lambda_1\|=true \land  \|\lambda_2\|=true) = \exists val. (val=req \land val=5) = (req=5)$, i.e., conditions $(val=req)$ and $(val=5)$ can only hold simultaneously if $(req=5)$. We have discovered a new predicate $req=5$ that must hold in states where abstract label $l$ is available.  We introduce a new untracked variable $\omega_2$, $\|\omega_2\|=(req=5)$ and refine $C^{M-}$ with a new consistent transition: $C^{M-} \gets C^{M-} \lor (\omega_2 \land \lambda_1 \land \lambda_2)$.
    \qed
\end{ex}

\subsection{Refining the Abstraction}
\label{sec:refineAbstraction}

The \textsc{refineAbstraction} function is invoked by the abstraction refinement algorithm when no further consistency refinements are possible.  At this point, every untracked sub-state of the boundary region is either must-winning or must-losing, i.e., can be coloured white or black using notation of Figure~\ref{f:crefinement}.  \textsc{refineAbstraction} promotes a subset of untracked predicates making sure that the winning region $W^M$ expands after re-solving the game in line~2 of Algorithm~\ref{alg:generic}.  

The procedure is identical to the refinement procedure for variable abstraction in Section~\ref{sec:variable_abstraction} so it is not given in detail here.

Algorithm~\ref{alg:refineAbstraction} shows the pseudocode of \textsc{refineAbstraction}.  Line~2 computes all untracked boundary substates that are must-predecessors of $W^M$.  Here, $CpreU^{M-}$ is the same as $Cpre^{M-}$ (Equation~\ref{e:cpreM}), but without untracked variable quantification:

$$
    \small
\begin{aligned}
    CpreU_i^{M-}(\phi) = &\abstractM{\tau_i}         \land \exists \vect{\lambda},\vect{\sigma'}. ((C^{M-} \land \Delta) \land \phi')
                          ~~\lor\\
                         &\abstractM{\tau_{\overline{i}}} \land \forall \vect{\lambda},\vect{\sigma'}. ((C^{m+} \land \Delta) \rightarrow \phi')
\end{aligned}
$$

We aim to grow  $W^M$ by promoting as few untracked predicates as possible.  To this end, we extract a short prime implicant from $U^M$ and promote the untracked variables in the support of the prime implicant (line~3).  This has the effect of adding a large cube over state and untracked predicates to $W^M$. The \textsc{promote} function invoked on line~4 moves the selected untracked predicates to the set of state predicates $\Sigma$ and recomputes the abstraction transition relation $\Delta$ for the new state predicates.  This can lead to the introduction of new untracked and label predicates, which can serve as refinement candidates in the future.

\begin{algorithm}[t]

\caption{Pseudocode of \textsc{refineAbstraction}}
\label{alg:refineAbstraction}

\begin{algorithmic}[1]

\Function{refineAbstraction}{$W^M$}
    \State $U^M \gets CpreU_1^{M-}(W^M) \land \overline{W^M}$
    \State $toPromote \gets \vect{\omega}~\cap~$\Call{support}{\textsc{shortPrime}($U^M$)}
    \State $\Call{promote}{toPromote}$
\EndFunction

\end{algorithmic}
\end{algorithm}

We must be careful when refining the abstraction. Do our consistency constraints remain valid after the abstraction has been refined? The following example shows that in some cases they do not.

\begin{ex}
    Consider an abstraction of the running example game induced by abstract variable $\sigma_1$ with corresponding predicate $\|\sigma_1\| = (req=dat)$ as well as the abstract label variable $\lambda_1$ with corresponding predicate $\|\lambda_1\| = (val=req)$. There are no untracked variables.

    Our must consistency constraint, $C^{M-}$, is a relation over the variables $\sigma_1$ and $\lambda_1$. For example, the tuple $v=(true), l=(true)$ is must consistent because it is always possible to assert $\lambda_1=true$ when $\sigma_1=true$ by choosing $val$ appropriately.

    Suppose, when computing the update function for some variable that has just been promoted we introduce the abstract untracked variable $\omega_2$ with corresponding predicate $\|\omega_2\| = (req=5)$. This partitions each sub-state into two. The definition of $C^{M-}$ (Equation~\ref{eqn:cM}) ensures that if a label is must consistent in a given state before the variable promotion then it will be must consistent in each sub-state after the promotion. In this example, the tuples $v=(true), u=(false), l=(true)$ and $v=(true), u=(true), l=(true)$ are both must consistent. Notice that, if we are symbolically representing $C^{M-}$, then the new $C^{M-}$ does not depend on the newly introduced untracked variable. Thus, we may keep the same $C^{M-}$ from before the promotion.

    The situation is not so good for promotions that introduce new label variables. We cannot simply reuse $C^{M-}$ from before the variable promotion as we do for untracked variables. Consider what happens when, continuing on from before, we add $\lambda_2$ with corresponding predicate $\|\lambda_2\| = (val=5)$. The tuple $v=(true), u=(true), l=(true)$ is must consistent. Extending the tuple to $v=(true), u=(true), l=(true, true)$ is fine, but $v=(true), u=(true), l=(true, false)$ is not. The latter tuple is not must-consistent. Therefore, we may not simply reuse $C^{M-}$ as in the case where an untracked variable is added. 

    We can rebuild $C^{M-}$ by considering all possible tuples with the additional label. In this case as there are few variables this would work and we would discover that the second tuple above is not part of $C^{M-}$. However, when there are more variables this is infeasible. 
    \qed
\end{ex}

From this example, we make two important observations. When compiling the update function for a untracked predicate that is being promoted to a state predicate when refining the abstraction, 

\begin{itemize}
    \item if the compilation only introduces new untracked predicates, then we can keep the consistency relations from the previous iteration.
    \item if the compilation introduces new label predicates, then we cannot reuse $C^{M-}$ from the previous iteration without modification.
\end{itemize}

We resort to conservatively resetting $C^{M-}$ to $false$ when a new label variable is added and incrementally rebuilding $C^{M-}$ lazily as before. This is a severe performance impediment as $C^{M-}$ may have to be rebuilt many times. We present a pragmatic solution to this problem that is used by Termite in Section~\ref{sec:optimisation}.

\subsection{Checking Containment of the Initial Set}
\label{sec:init_containment}

We create an abstraction of the initial set by introducing a boolean state variable for each predicate that appears in the expression for the initial set. We then replace each predicate by the corresponding boolean variable.

The approximate three valued abstraction-refinement algorithm must check whether the winning set contains the initial set. This check is performed for both winning sets in Algorithm~\ref{alg:approx_three_val}. Again, predicate abstraction complicates things as the following example shows.

\begin{ex}
    Consider an abstraction of the running example induced by the abstract variables $\sigma_1$, $\sigma_2$ and $\sigma_3$ and corresponding predicates $\|\sigma_1\| = (req=dat)$, $\|\sigma_2\| = (req=mem)$ and $\|\sigma_3\| = (dat=mem)$. The initial set is specified as $req=dat \land req=mem$ which is abstracted to $\sigma_1 \land \sigma_2$. Suppose that the may winning set of states, $W^{m+}$, that the game solving algorithm returns is $\{v=(true, true, true)\}$. Importantly, this set does not contain $v=(true, true, false)$. Naively, we might check if the initial set implies the winning set, i.e., if $(\sigma_1 \land \sigma_2) \rightarrow W^{m+}$. However, as $\sigma_1 \land \sigma_2 \land \neg\sigma_3$ is not part of $W^{m+}$, this implication is false i.e. $(\sigma_1 \land \sigma_2) \centernot\rightarrow (\sigma_1 \land \sigma_2 \land \sigma_3)$.

    We should have ignored the losing state $v=(true, true, false)$ when checking if the winning set consumes the initial set as it is inconsistent and does not correspond to any real states in the concrete game. 
    \qed
\end{ex}

As the example shows, checking if the initial set implies each of the winning sets is not correct. Instead, we find a witness losing state and we then check consistency of this state. The algorithm is given in Algorithm~\ref{alg:initial_inclusion}. 

In line~\ref{a:init_incl:l:imp} we check if the abstraction of the initial set is a subset of the abstraction of the given winning set. If so, we return True.

If it is not, we extract a witness state on line~\ref{a:init_incl:l:implicant}. We check consistency of the state on line~\ref{a:init_incl:l:sat}. If the state is consistent, then we have found at least one losing concrete state. Otherwise, we extract an unsatisfiable core on line~\ref{a:init_incl:l:core} and add this to a consistency constraint that prevents this and other states from being selected as witnesses in the future. We then recurse with the updated consistency constraint on line~\ref{a:init_incl:l:recurse}. Effectively, we have another refinement loop that iteratively refines a consistency relation over states. 

\begin{algorithm}
\caption{Checking inclusion of the initial set}
\label{alg:initial_inclusion}

\begin{algorithmic}[1]

\Function{refineInit}{$W$, $Init$, $inconsistent$}
\If{$Init \rightarrow W$} \label{a:init_incl:l:imp}
        \State\Return $True$
    \Else
        \State $witnesses \gets Init \land \neg W \land \neg inconsistent$ \label{a:init_incl:l:witness}
        \State $implicant \gets \Call{primeImplicant}{witnesses}$ \label{a:init_incl:l:implicant}
        \If{$\Call{satisfiable}{implicant}$} \label{a:init_incl:l:sat}
            \State\Return $False$
        \Else
            \State $inconsistent \gets inconsistent \lor \Call{unsatCore}{implicant}$ \label{a:init_incl:l:core}
            \State\Call{refineInit}{$W$, $Init$, $inconsistent$} \label{a:init_incl:l:recurse}
        \EndIf
    \EndIf
\EndFunction

\end{algorithmic}
\end{algorithm}

\subsection{Initial Abstraction}

We obtain the initial abstraction by extracting atomic predicates from expressions $T$, and $\tau_i$, which guarantees that the abstraction is precise for $T$, and $\tau_i$. While this property is not essential for our approach, we will rely on it to simplify the presentation of the algorithm.

The initial state and label predicates are those that are created during compilation of the update functions for these predicates.

Finally, we assign $C^{m+}=\top$ and $C^{M-}=\bot$ initially.

\subsection{Putting it Together}

The Algorithm for three valued predicate abstraction-refinement is given in Algorithm~\ref{alg:final}. In lines~\ref{a:final:l:must} and~\ref{a:final:l:may} we compute the must and may winning sets. We then check if the initial set is a subset of the must winning set using the procedure described in Section~\ref{sec:init_containment} on line~\ref{a:final:l:term1}. If it is, we terminate as the game is winning. We then check if the initial set is a subset of the may winning set using the same procedure on line~\ref{a:final:l:term2}. If it is not, we terminate as the game is losing. Finally, if none of the termination conditions are met, we refine. First, we attempt to refine the consistency constraints on line~\ref{a:final:l:refcpre} using the procedure described in Section~\ref{sec:cons_refinement}. If that fails, we refine he abstraction on line~\ref{a:final:l:refabs} using the procedure described in Section~\ref{sec:cons_refinement}.

Finally, to arrive at the Termite game solver, we extend the algorithm to GR(1) games in the same way we did for variable abstraction.

\begin{algorithm}
\caption{Three-valued abstraction refinement for games.}
\label{alg:final}

\begin{algorithmic}[1]

\Require A game structure $G = \langle S, L, I, \tau_1, \tau_2, \delta \rangle$, a set of target states $T\subseteq S$, and an initial abstraction $\alpha=\langle V, \concrete{}, Cpre_1^{m+}, Cpre_1^{M-} \rangle$ that is precise for $T$, $I$, and $\tau_i$.

\Ensure {\it Yes} if $I \subseteq \reach(T, Cpre_1)$, and {\it No} otherwise.

\Function{Solve}{$transitionRelation$, $goal$}
    \Loop
        \State $W^M \gets \reach(T, Cpre_1^{M-})$             \label{a:final:l:must}
        \State $W^m \gets \reach(T, Cpre_1^{m+})$             \label{a:final:l:may}
        \If{$\Call{refineInit}{W^M, I, inconsistentInit}$}    \label{a:final:l:term1}
            \State\Return Yes
        \ElsIf{$\Call{refineInit}{W^m, I, inconsistentInit}$} \label{a:final:l:term2}
            \State\Return No
        \Else       
            \State $refined \gets \Call{refineCpre}{W^M}$     \label{a:final:l:refcpre}
            \If {$(\neg refined)$}
                \State$\Call{refineAbstraction}{W^M}$         \label{a:final:l:refabs}
            \EndIf
        \EndIf
    \EndLoop
\EndFunction

\end{algorithmic}
\end{algorithm}


\subsection{Correctness}

The correctness and termination theorems of~\cite{Alfaro_Roy_07} hold for Algorithm~\ref{alg:generic} with \textsc{refineCpre} and \textsc{refineAbstraction} functions defined above.

\begin{theorem}

If Algorithm~\ref{alg:generic} terminates, it returns the correct answer.

\end{theorem}

\begin{proof}

By construction, $Cpre_i^{m+}$ and $Cpre_i^{M-}$ over- and under-approximate abstract controllable predecessor operators, i.e., $\concrete{Cpre_i^m(\phi)} \subseteq \concrete{Cpre_i^{m+}(\phi)}$ and $\concrete{Cpre_i^{M-}(\phi)} \subseteq \concrete{Cpre_i^M(\phi)}$, for any set $\phi$.  Hence, winning sets $W^m = \reach(\abstractm{T}, Cpre_1^{m+})$ and $W^M = \reach(\abstractM{T}, Cpre_1^{M-})$ computed using these operators over- and under-approximate the winning set $W$ of the concrete game: $\concrete{W^M}\subseteq W \subseteq \concrete{W^m}$.  

If the algorithm returns \emph{Yes} then the initial set of the game is a subset of the must-winning region ($I\subseteq \concrete{W^M}$) and hence $I\subseteq W$.  Likewise, if the algorithm returns \emph{No} then $I\not\subseteq \concrete{W^m}$ and hence $I\not\subseteq W$.  In both cases the answer produced by the algorithm is correct.

\end{proof}

\begin{theorem}
\label{t:termination}

If there exists a finite region algebra $\mathcal{A}$ such that all abstractions $\langle V, \concrete{}\rangle$ produced by Algorithm~\ref{alg:generic} are contained in $\mathcal{A}$ then the algorithm terminates.

\end{theorem}

\begin{proof}[Proof outline]

Let $W^M$ and $\hat{W}^M$ be must-winning sets computed at two subsequent iterations of Algorithm~\ref{alg:generic}.  

We first show that refinement procedures \textsc{refineCpre} and \textsc{refineAbstraction} guarantee that the must-winning set computed at every iteration of the refinement loop grows monotonically, i.e., $\concrete{W^M} \subseteq \concrete{\hat{W}^M}$.  This follows from the soundness of the refinement procedures, which improve the precision of $Cpre_i^{M-}$ at every iteration. 

Next we show that the algorithm is guaranteed to make forward progress, i.e., after a finite number of refinements it either terminates or discovers new must-winning states ($\concrete{W^M} \subset \concrete{\hat{W}^M}$).  Consider the consistency refinement procedure \textsc{refineCpre} first.  Every invocation of this procedure classifies some of the untracked substates at the may/must boundary as either must-winning or must-losing (see Figure~\ref{f:crefinement}).  Eventually, it will either classify all boundary states as must-losing, in which case $\concrete{W^m} = W = \concrete{W^M}$, and the algorithm terminates, or find at least one must-winning sub-state (as in Figures~\ref{f:crefinement}c and~\ref{f:crefinement}d).  In the latter case, a subsequent invocation of the abstraction refinement procedure \textsc{refineAbstraction} is guaranteed to partition one of the boundary states so that one of the resulting abstract states is must-winning.  This state will be discovered at the next run of the reachability algorithm, thus expanding the must-winning set.

Since, by the assumption of the theorem, all must-winning sets $W^M$ generated by the algorithm belong to a finite region algebra, the algorithm is guaranteed to terminate after a finite number of iterations.

\end{proof}

The theory of fixed-size bit vectors supported by our current implementation satisfies the premise of Theorem~\ref{t:termination}, which guarantees the termination of the algorithm.

\section{Optimisation}
\label{sec:optimisation}

Algorithm~\ref{alg:refineCpre} has two important performance issues: 

\begin{itemize}

    \item Every time an untracked variable is promoted, if a new label variable is created in the process, $C^{M-}$ must be reset to False.

    \item In lines~10--16 it analyses and adds to $C^{M-}$ a single abstract label $l$.  The set of all abstract labels is exponential in size in the number of label predicates and can be very large in practice, making explicit enumeration infeasible.  

\end{itemize}

To address the first issue, we modify the algorithm to handle a set of abstract labels at every iteration.  To this end, in line~7, instead of choosing a complete assignment to state, untracked, and label predicates, we compute a \emph{prime implicant} of set $T$, i.e., an assignment to a subset of variables in $\vect{\sigma}\cup\vect{\omega}\cup\vect{\lambda}$ such that any extension of this assignment to the remaining variables satisfies $T$: 
$$
\langle v,u,l\rangle \gets \textsc{primeImplicant}(T),
$$ 
where $v$, $u$, and $l$ are partial valuations of abstract variables, which compactly represent a potentially large set of abstract transitions.  In practice, we typically discover prime implicants that only constrain few of the abstract variables, meaning that other predicates are irrelevant for the outcome of the transition.  

Given this modification, the $C^{m+}$ refinement case of the algorithm (lines~18--19) is still correct and does not require any changes.  However, changes are needed in the $C^{M-}$ refinement logic.  The set $A$ computed in lines~10--1 contains all concrete states where \emph{at least one} abstract label from the set characterised by the partial assignment $l$ of label predicates is available.  It does not guarantee the availability of any particular label from this set.  To model this constraint, we would have to change $C^{M-}$ to be a relation over sets of labels.  Every element of the relation would describe a set of labels, one of which is guaranteed to be available for the given state and untracked predicate assignment.  

This introduces a new form of imprecision to the consistency relation: rather than categorising each abstract label as available or unavailable in the given state, we record a set of labels, one of which is available.  However, such a relation would be hard to represent and manipulate efficiently in the symbolic form.  Therefore, we propose a different approach that allows symbolic implementation.  

We transform the game (without changing its winning set) in order to solve it more efficiently.  The idea of our solution is to model the new form of imprecision as non-determinism in the abstract transition relation $\Delta$.  For each abstract label variable $\lambda_i$, we introduce an auxiliary \emph{enabling variable} $\varepsilon_i$ and transform the transition relation $\Delta$ as follows:
$$
\Delta \gets (\varepsilon_i \land \Delta) \lor (\overline{\varepsilon_i} \land \exists \lambda_i. \Delta).
$$
When $\varepsilon_i=true$, $\Delta$ behaves exactly as before.  In case $\varepsilon_i=false$, the value of $\lambda_i$ chosen by the player is ignored and the environment non-deterministically selects next-state variables assignment that is consistent with \emph{some} assignment of $\lambda_i$. 

We can now modify line~16 of Algorithm~\ref{alg:refineCpre} as follows:
$$
C^{M-} \gets C^{M-} \lor (\hat{A}\land \bigwedge_{i\in{j_1\ldots j_p}}\lambda_i=l_i \land \bigwedge_{i\not\in{j_1\ldots j_p}}\varepsilon_i=false),
$$
where $j_1\ldots j_p$ are indices of variables assigned by $l$.  The above statement refines $C^{M-}$ by allowing the player to assign a subset of label variables in accordance with $l$ and disabling other label variables not constrained by $l$.  The environment will non-deterministically pick arbitrary values for these variables.  In this way we precisely capture what we currently know about consistent predicate assignments in a symbolic form, at the cost of introducing extra variables $\varepsilon_i$.

\section{Implementation}
We implemented this abstraction refinement algorithm as part of Termite. Termite currently supports specifications in its own domain-specific Termite Specification Language (TSL), which is described in Appendix~\ref{ch:tsl_ref}.

We extended our abstraction-refinement algorithm to handle GR(1) games as outlined in Section~\ref{sec:omega_reg}.

Termite currently supports input specifications over the concrete domain of fixed-size bit vectors and arrays.  We use the Z3 SMT solver to check satisfiability and retrieve unsatisfiable cores of formulas over concrete variables (lines~\ref{a:refineCpre:sat} and~\ref{a:refineCpre:core} of Algorithm~\ref{alg:refineCpre}).  Quantifier elimination (line~\ref{a:refineCpre:quant}) over bit vector formulas is performed using our custom implementation of the decision procedure for bit vectors by Barrett et al.~\cite{Barrett_DL_98}.  Termite interacts with the theory solver through a well-defined interface and hence can be readily extended with additional theories.  All computations over the abstract domain are performed symbolically using the CUDD BDD package.  

In addition to the techniques described for variable and predicate abstraction implemented the optimisations described in Section~\ref{sec:syntcomp_optimisations}.

We also implemented an optimised version of the original algorithm by de~Alfaro and Roy, as described in Section~\ref{sec:variable_abstraction}, which enables a direct comparison of the two techniques.

The core abstraction-refinement algorithm consists of 1800 lines of Haskell code.

\section{Evaluation}
\begin{sidewaystable}
    \small
    \center
\begin{tabular} {| l | l | r | r | r | r | r | r | r | r | r | r |}
    \hline
    \multirow{2}{*}{} & \multirow{2}{*}{Statistic} & \multicolumn{10} {|c|} {Case study} \\ \cline{3-12} & & \multicolumn{1}{c}{IDE} & \multicolumn{1}{c}{RTC} & \multicolumn{1}{c}{UART-1} & \multicolumn{1}{c}{UART-2} & \multicolumn{1}{c}{I2C-1} & \multicolumn{1}{c}{I2C-2} & \multicolumn{1}{c}{SPI} & \multicolumn{1}{c|}{UVC} & \multicolumn{1}{c|}{simple SPI} & \multicolumn{1}{c|}{simple I2C} \\
    \hline \hline
    1  & concrete state vars (bits)                   & 83 (952) & 64 (624) & 61 (335) & 65(896) & 64 (458) & 50(222) & 66(644) & 95 (75908) & 7 (46) & 11 (64) \\ 
    2  & concrete label vars (bits)                   & 27 (389) & 24 (199) & 20 (86)  & 15(289) & 25 (199) & 15(81)  & 24(384) & 33 (49657) & 9 (58) & 14 (42) \\ 
    3  & consistency refinements                      &     11   &      9   &     42   & 4       &     12   & 4       & 6       & 22         & 0      & 23 \\ 
    4  & state refinements                            &     18   &     16   &     18   & 50      &     15   & 17      & 26      & 25         & 11     & 9  \\ 
    5  & state predicates                             &     31   &     25   &     33   & 58      &     24   & 24      & 31      & 30         & 14     & 17 \\ 
    6  & label predicates                             &     57   &     41   &     40   & 53      &     36   & 32      & 28      & 130        & 19     & 36 \\ 
    7  & untracked predicates                         &      7   &      4   &     35   & 2       &      5   & 1       & 6       & 32         & 0      & 0  \\ 
    8  & run time (s)                                 &     71   &     74   &    309   & 603     &     39   & 43      & 14      & 190        & 1      & 10 \\ 
    9  & peak BDD size                                & 864612   & 515088   & 907536   & 1142596 & 440482   & 688828  & 324996  & 785918     & 87892  & 242214 \\
    \hline
    \multicolumn{2} {|c} {} & \multicolumn{10} {c|} {Performance of the de~Alfaro and Roy algorithm~\cite{Alfaro_Roy_07}} \\
    \hline
    10 & run time (s)                                 & $\infty$ & $\infty$ & $\infty$ & $\infty$& $\infty$ & $\infty$& $\infty$& $\infty$   & 865    & 1151 \\ 
    11 & peak BDD size                                &  -       & -        & -        & -       & -        & -       & -       & -          & 400624 & 4088000 \\
%    10 & concrete state vars in predicates (bits)     & 26 (262) & 24 (190) & 27 (156) & & 26 (206) & & & 39 (25556) \\
%    11 & concrete label vars in predicates (bits)     & 24 (341) & 23 (191) & 16 (82)  & & 25 (199) & & & 30 (25095) \\
%    Size of winning BDD                    &    108 &     98 &    %    202 & \\ 
    \hline
\end{tabular}
\caption{Summary of experimental case studies.}
\label{t:exp}
\end{sidewaystable}

We evaluate our synthesis algorithm by synthesising drivers for several real-world I/O devices, including an IDE hard disk, a real-time clock, two UART serial controllers, two I2C bus controllers, an SPI bus controller, and a UVC webcam.  We developed corresponding device and OS models using the Termite Specification Language (TSL) by following the common methodology used by hardware developers in building high-level device models.  We refer the reader to Appendix~\ref{ch:tsl_ref} for a description of the TSL language and the modelling methodology.  The source code of the case studies is available as part of the Termite distribution~\cite{termite}.

Table~\ref{t:exp} summarises our experiments.  The first two rows characterise the complexity of the input models in terms of the number of variables and the total number of bits used in the concrete specification of the game.  Concrete state variables model internal device state, as well as the state of the driver-OS interface; label variables model commands and responses exchanged by the driver, the device, and the OS.  

Rows~3 and 4 show the number of iterations of the abstraction refinement loop required to solve the game.  Rows~5 through 7 show the size of the abstract game at the final iteration, when a winning strategy for the driver was obtained, in terms of the number of state, label, and untracked predicates.  These results demonstrate the dramatic reduction of the problem dimension achieved by our abstraction refinement method.  The resulting abstract games are still too complex to solve using explicit state enumeration, hence the use of symbolic techniques is essential.  In all case studies, Termite was able to find the winning strategy within 11 minutes running on a 2.9GHz Intel Core i7 laptop (row~8), with peak BDD size under one million nodes (row~9).

The two final rows show the performance of the original three-valued variable abstraction refinement algorithm of de~Alfaro and Roy on our benchmarks.  As expected, the algorithm does not terminate on any of the real-world driver benchmarks within a two-hour time limit.  We therefore developed simplified versions of two of the benchmarks (SPI and I2C-2) with significantly reduced state spaces.  As shown in the last two columns of the table, the de~Alfaro and Roy algorithm terminates on these benchmarks; however it takes several orders of magnitude longer than our new algorithm, which uses predicate abstraction.  These results show that predicate abstraction is essential to solving complex real-world games.

