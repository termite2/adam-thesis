\chapter{Background}
\label{ch:background}

\section{Device Drivers}

A device driver provides an interface for the operating system (OS) to use a hardware device that is attached to the computer. It translates requests between the OS and the hardware. It allows the operating system to use the device without knowing the exact details of the hardware. As an example, a network interface driver may provide functions to send and receive packets from the network. It performs the low-level device register and memory writes necessary to perform these operations while presenting a high level interface to the OS.

Writing a device driver requires in depth knowledge of both the device to be controlled and the interface to the OS\@. This makes writing a device driver a tedious and error prone process. Additionally, a device driver usually operates in a privileged part of the OS so that it can access the hardware. As a result, errors often lead to failures of the system.

Device drivers are usually developed by the hardware vendor as they have the best access to information about the design of the hardware. This includes hardware documentation as well as the actual description of the hardware in a hardware description language. It is common for the documentation to never be released to the public.

\subsection{Device driver functions}

The key functions of a device driver are:
\begin{itemize}
    \item \emph{Abstraction.} As discussed, the driver abstracts away the low-level details of the device and presents the functionality through a high level set of operations.
    \item \emph{Unification.} The driver provides a unified interface to similar devices. For example, another network interface may have a completely different hardware interface to the first but its driver presents the same send and receive functionality to the OS as before. 
    \item \emph{Multiplexing.} The driver and OS cooperate to make sure that the services that the hardware provides are available to all users of the system with sufficient permissions to access the hardware.
\end{itemize}

\subsection{Device driver organisation}
\subsubsection{I/O buses}

Device drivers communicate with devices over an I/O bus such as the \emph{Peripheral Component Interconnect} (PCI) or \emph{Universal Serial Bus} (USB). Modern operating systems contain drivers that operate these buses and provide low-level access to devices over them. In this thesis I assume that these-bus level drivers already exist. 

\subsubsection{Memory Mapped I/O}

Device registers and data buffers can be mapped into the system's memory space by the bus controller. When the CPU initiates a load or store transaction which falls in the range of memory mapped to the device the bus controller translates this to a transaction with the device. This transaction reads and writes the device's internal registers.

\subsubsection{Direct Memory Access}

It is also possible for the device to initiate a transaction to transfer data to or from main memory. The CPU is not involved in such a transfer. This is known as \emph{Direct Memory Access} or DMA\@. DMA is necessary for efficient I/O with devices that transfer large amounts of data as otherwise the CPU would be required to copy all of the data to and from the device word by word.

\subsubsection{Interrupts}

\emph{Interrupts} are asynchronous transactions initiated by the device to signal to the CPU that an event has happened that requires the driver's attention. For example, a network interface may raise an interrupt when a packet has arrived or when a packet has been successfully sent. Interrupts are also often raised on error conditions within the device.

On a Linux system, when an interrupt is raised, the currently executing task is temporarily suspended and control is transferred to the kernel's interrupt handler routine. This determines which driver is responsible for handling the interrupt and invokes the driver's interrupt handler.

\subsubsection{Concurrency}

Most operating systems are multithreaded, including the device drivers. Driver entry points and interrupt handlers may be invoked concurrently and recursively. Careful use of synchronisation primitives are required to avoid race conditions and deadlock. In this work, I assume that only one driver entry point is invoked at a time, removing all concurrency. This can be achieved by using an event based framework such as Dingo \cite{Ryzhyk_CKH_09}, writing a wrapper to translate the concurrent interface required by the operating system to the single threaded interface of the generated drivers, or by post processing the generated driver as described by \cite{Cerny_HRRT_13, sched-cav, scheduling-cav15}

\subsubsection{Operating system services}

In addition to bus-level drivers, the OS provides various services to device drivers. These include memory management, timing and synchronisation. Memory management includes allocating memory and support for memory mapped IO and DMA\@. Timer functionality includes both synchronous (thread delays) and asynchronous (callback) timers. Various synchronization primitives are also provided, but, given that Termite does not make any use of them, I do not discuss them further.

\section{Introduction to Game Formalisms}

Termite's game formalism and synthesis algorithm build on considerable pre-existing work in the field of reactive synthesis which is presented in the following sections. I begin, in Sections~\ref{sec:omega_regular} and~\ref{sec:two_player} by introducing the notion of $\omega$-regular games.  Section~\ref{sec:omega_regular} introduces $\omega$-regular languages and $\omega$-regular expressions offer a natural formalism for reasoning about reactive systems, i.e., systems that continuously interact with their environment, such as device drivers.  
%In Termite, $\omega$-regular languages are used to specify requirements for correct driver behaviour.
Section~\ref{sec:two_player} defines two player $\omega$-regular games, i.e., games whose objectives are expressed using $\omega$-regular languages.  Starting from the simplest kinds of games, it eventually builds up to GR(1) games - the kind of games used by Termite. Definitions for this and the following sections are given in \cite{Gradel} and \cite{Thomas_95}. GR(1) games are discussed in depth in \cite{Piterman_PS_06}.

Section~\ref{sec:symbolic_games} introduces symbolic techniques. The idea of symbolic game solving is to represent sets of states using characteristic equations over state variables rather than by enumerating them explicitly. This technique allows game solvers to scale well beyond what was possible previously. The description of the data structure that is used to represent these characteristic equations is delayed to Section~\ref{sec:back_bdd}.

Sections~\ref{sec:fixed_points} and~\ref{sec:intro_solving} introduce algorithms for solving two-player games, i.e., determining whether one of the players can meet its objective.  I first define a logic for describing fixed points of functions in Section~\ref{sec:fixed_points}.  Next, in Section~\ref{sec:intro_solving}, I introduce the controllable predecessor operator, the fundamental building block of all game solving algorithms used in this thesis.  I then put the two together by presenting translations of $\omega$-regular game objectives to fixed point formulas over the controllable predecessor operator. The solution of a game can then be obtained by evaluating the fixed point formula.

%This, in turn, gives us algorithms for solving games, since a fixed point formula can be mechanically translates from a fixed point formula to an algorithm that evaluates it, .

%The winning set of states in a game with an $\omega$-regular objective can be described with a fixed point formula. Furthermore, there is a mechanical translation from a fixed point formula to an algorithm that evaluates it. Fixed-point formulas are thus a useful tool for defining $\omega$-regular objectives and describing the algorithms to compute winning regions.  It then uses this to present translations of the objectives to \mucalc formulas which, in turn, gives us algorithms to solve them.
%
%Section~\ref{sec:intro_solving} presents the controllable predecessor operator, the fundamental building block of all game solving algorithms used in this thesis. It then uses this to present translations of the objectives to \mucalc formulas which, in turn, gives us algorithms to solve them.

In addition to deciding whether there exists a correct driver for a set of specifications, Termite must synthesize a strategy which will be turned into driver code. In Section~\ref{sec:strat_and_cex2} I modify the algorithms given in the previous section to return a strategy if the game is winnable. I also show how to generate a strategy for the opponent, called a counterexample, when the game is not winnable. Counterexamples are used extensively in Termite to aid in debugging faulty specifications.

Finally, Section~\ref{sec:back_bdd} introduces binary decision diagrams (BDDs). BDDs are an efficient algorithm for representing sets and relations symbolically. They are used extensively in Termite. BDDs and the algorithms that operate on them are given in \cite{Bryant_86}. Symbolic model checking utilising BDDs is discussed in depth in \cite{Burch_symbolic} and \cite{McMillan_thesis}.

\section{$\omega$-regular Languages}
\label{sec:omega_regular}

The $\omega$-regular languages extend the regular languages to infinite length sequences. An $\omega$-regular language is a set of sequences of symbols of infinite length. An $\omega$-regular language has the form:
\begin{itemize}
    \item $A^\omega$ where $A$ is a nonempty regular language not containing the empty string.
    \item $AB$, the concatenation of a regular language $A$ and an $\omega$-regular language $B$. Note that $B$ must not be a regular language as this would imply that the sequence is finite.
    \item $A \cup B$ where $A$ and $B$ are $\omega$-regular languages.
\end{itemize}

Elements of $A^\omega$ are obtained by concatenating words from $A$ infinitely many times. Intuitively, $\omega$-regular languages are similar to regular languages but with an additional $\omega$ operator that concatenates words from the regular language infinitely many times.

\section{Two Player Games}
\label{sec:two_player}

Two-player games are a useful formalism for reactive synthesis. Many problems in electronic design automation, industrial automation, software synthesis and robotics can be formalised as a game. In particular, the driver synthesis problem can be formalised as a game, and, this is the formalism around which Termite is built. Here, I present the fundamentals of two player games. 

\subsection{Formalism}
\label{sec:intro_formal}

A two player game is played by player~1 against its opponent, player~2. It consists of a possibly infinite state space $S$ on which the game is played. The game is always in some state $s \in S$ called the \emph{current state}. The game progresses from state to state according to a transition relation, $\delta \subseteq S \times L \times S$ where $S$ is the set of states and $L$ is a set of labels. A transition $t \in S \times L \times S$ is allowed in the game iff $t \in \delta$. 

The meaning of the label $l \in L$ depends on the type of game, but for now we will consider turn based games. In a turn based game, $S$ is partitioned into two sets: the player~1 set $\tau_1$ and the player~2 set $\tau_2$, where $\tau_1 \cap \tau_2 = \emptyset$ and $ \tau_1 \cup \tau_2 = S$. When $s \in \tau_1$ player 1 gets to pick $l$ and when $s \in \tau_2$ player 2 gets to pick $l$. The opponent of player $i$ is referred to as $\overline{i}$ ($\overline{1} = 2$, $\overline{2} = 1$).

Lastly, each game has an associated set of initial states $I \in 2^S$ where execution of the game begins.

Putting this all together, we can identify a \emph{turn based game structure} $G = \langle S,L,I,\tau_1,\tau_2,\delta \rangle$ with a turn based game.

A game proceeds in an infinite sequence of rounds, starting from some initial state. The infinite sequence of states visited $(s_0, s_1,\ldots) \in S^\omega$ such that $\forall i.\ \exists l.\ (s_i, l, s_{i+1}) \in \delta$ is called a path. An \emph{objective} $\Phi \subseteq S^\omega$ is a subset of state sequences of $G$. We are concerned with $\omega$-regular objectives, i.e., objectives characterised by $\omega$-regular languages (Section~\ref{sec:omega_regular}). 

A \emph{strategy} for player~$i$ is a function $\pi_i : S^* \times \tau_i \rightarrow L$ that, in any player~$i$ state, associates the history of the game with a label to play. The set of initial states $I$ and a player~$i$ strategy $\pi_i$ determines a set $Outcomes_i(I, \pi_i)$ of paths $s_0, s_1, s_2, \ldots $ such that $s_0 \in I$ and $(s_k, \pi_i(s_0,\ldots,s_k), s_{k+1}) \in \delta$ when $s_k \in \tau_i$ and $(s_k, l, s_{k+1}) \in \delta$ for some $l$ when $s_k \in \tau_{\overline{i}}$.  Given an objective $\Phi \subseteq S^\omega$ we say that state $s \in S$ is winning for player $i$ if there is a strategy $\pi_i$ such that $Outcomes_i({s}, \pi_i) \subseteq \Phi$. That is, if, by picking suitable labels, they can force the path to be within the set of winning sequences. An arbitrary set of infinite sequences is an extremely general, but not practically useful, way of defining an objective. In the following sections we will consider some more restricted objectives that have practical uses.

\subsection{Safety and reachability}
\label{sec:back_safety}

The two simplest objectives are safety and reachability. A safety objective is defined by a set $\safeobj \subseteq S$ that player 1 must force the game to stay within, regardless of the labels that player 2 picks. Formally, a run is safe if 

\begin{equation}
\label{eqn:safeobj}
\forall i.\ s_i \in \safeobj
\end{equation}

The dual of a safety objective is a reachability objective. A reachability objective is defined by a set $\reachobj \subseteq S$ that player 1 must force the game to visit at least once, regardless of the labels that player 2 picks. Formally, a reachability run is winning if 

\begin{equation}
\label{eqn:reachobj}
\exists i.\ s_i \in \reachobj
\end{equation}

\paragraph{\buchi}
\label{sec:buchi_def}
A \buchi\ objective is defined by a set $\buchiobj \subseteq S$ that player~1 must always be able to force execution of the game into. This differs from a reachability game in that the region must always be reachable, not just once. When it has been reached once, it must be reachable again, and so on. So, it must be reachable infinitely many times. Formally, a run is \buchi\ winning if 

\begin{equation}
\forall i.\ \exists j>i.\ s_j \in \buchiobj
\end{equation}

\paragraph{Generalised \buchi}
A Generalised \buchi\ objective is defined by a finite set of sets $\genbuchiobj \subseteq 2^S$. Player~1 must always be able to force execution into each set $\buchiobj \in \genbuchiobj$. Formally, a run satisfies a generalised \buchi\ objective if 

\begin{equation}
\forall i.\ \forall \buchiobj \in \genbuchiobj.\ \exists j>i.\ s_j \in \buchiobj
\end{equation}

\paragraph{Fairness}
\label{sec:fairness}
Sometimes it is necessary to rule out invalid plays that are not easily ruled out by changing the state machine. As an example, consider a progress assumption that guarantees that the game will eventually leave a set of `pending' states. For this we use fairness conditions. A fairness condition is a set of states, the \emph{fair} set, which we may assume that all valid runs of the game eventually enter. Or, equivalently, a set of states, called the \emph{unfair} set which we may assume that all valid runs of the game eventually leave. The player can assume that all executions of the system are fair and hence they only need to satisfy the objective of the game in fair runs. Formally, a run satisfies a fair reachability objective if 

\begin{equation}
\forall i.\ \exists j>i.\ s_j \in \fairobj \rightarrow \exists i.\ s_i \in \reachobj
\end{equation}

\paragraph{GR(1)}
\label{sec:gr1}
A Generalised Reactive 1, or GR(1) \cite{Piterman_PS_06} objective, is a generalised \buchi\ objective with multiple fairness conditions. In practice, this turns out to be a very useful type of objective with specifying the requirements of device drivers. This is because it captures the notion that the driver must satisfy requestes indefinitly while at the same time relying on guarantees provided by the environment in order to satisfy those requests. Formally, given a set $FAIRS$ of fair sets of states, a run satisfies a GR(1) objective if 

\begin{multline}
\forall i.\ \forall \fairobj \in \genfairobj.\ \exists j>i.\ s_j \in \fairobj \rightarrow \\ \forall i.\ \forall \buchiobj \in \genbuchiobj.\ \exists j>i.\ s_j \in \buchiobj
\end{multline}

Informally, a run is winning in a GR(1) game if for all fair runs the generalised \buchi\ condition holds.

\subsection{Perfect information games}

Perfect information games are two player games where both players know the current state of the transition system at all times. We will assume that all games are perfect information games.

\subsection{Strategies and counterexamples}
\label{sec:strat_and_cex}

It is known that for perfect information safety, reachability and \buchi\ games, if there exists a strategy, then there also exists one that only depends on the current state \cite{Gradel}. Thus, we can simplify the definition of a strategy in this case for player~1 to be a function $\pi_1 : \tau_1 \rightarrow L$ that only depends on the current state.

Furthermore, for the case of generalised \buchi\ and GR(1) games, if there exists a strategy, then there also exists one that only depends on the current state and some finite additional state (Section~\ref{sec:genbuch}). We can simplify the definition of a strategy in this case for player~1 to be a function $\pi_1 : \tau_1 \times \sigma \rightarrow L \times \sigma$ that only depends on the current state and the finite additional state ($\sigma$), and, in addition to returning the label to play, returns the updated additional state.

Perfect information $\omega$-regular games are \emph{determined}. That is, the winning regions for player~1 and player~2 partition the set of game states \cite{Gradel}. This means that if a state is not winning for player~1, then it is winning for player~2 and there exists a strategy for player 2 to violate the objective.

This is known as a \emph{counterexample strategy}. It is a strategy for player~2 which ensures that player~1 cannot satisfy their objective. In the case of perfect information safety, reachability and \buchi\ games, if there exists a counterexample strategy (or, equivalently if the game is not winnable for player~1) then there exists a counterexample strategy that only depends on the current state. This is a function $\pi_2 : \tau_2 \rightarrow L$ that associates any player~2 state with a label for player~2 to play. 

Again, in the case of generalised \buchi\ and GR(1) games, the counterexample strategy may depend on an additional finite state: $\pi_1 : \tau_2 \times \sigma \rightarrow L \times \sigma$.

\section{Symbolic Games}
\label{sec:intro_symb}
\label{sec:symbolic_games}

Defining and solving games requires representing sets of states (Section~\ref{sec:intro_formal}). Some of the games that have been solved with Termite have upwards of $2^{80}$ states, even after abstraction (Chapter~\ref{ch:solving}). Clearly, explicitly representing the state space will never succeed. Identical problems are encountered in model checking. The breakthrough that revolutionised model checking was to represent state sets and transition relations implicitly as a characteristic equation over state variables \cite{Burch_symbolic,McMillan_thesis}.

Symbolic games are defined over a finite set of state variables, $\symStateVars$, a finite set of label variables $\symLabelVars$. A \emph{valuation} for a set of variables $V$ is a function from each of those variables to an element of its domain. $S$, the set of states, is redefined to be the set of possible valuations of each state variable in $\symStateVars$. That is, each state $s \in S$ is given by a valuation of all of the state variables in $\symStateVars$. Similarly, $L$, the set of labels, is redefined to be the set of possible valuations of each label variable in $\symLabelVars$.

For a set $Z$ of variables, $\forms(Z)$ denotes the set of propositional formulas constructed from the variables in $Z$. The characteristic formula of a set of states $T$ is a function $f \in \forms(\symStateVars)$ that evaluates to true for the valuation corresponding to a state $s \in T$ and false otherwise. Characteristic formulas are used to represent sets of states without explicitly listing each member of the set. This is called a symbolic representation. 

Likewise, $\delta$ is specified by a formula in $\forms(\symStateVars \bigcup \symLabelVars \bigcup \symStateVars')$, where $\symStateVars' = \{\sigma' \mid \sigma \in \symStateVars \}$ is a copy of the variables in $\Sigma$ whose valuations represent allowable next state valuations of $\Sigma$.

Sometimes, the variables that a characteristic formula depends on are made explicit. For example, the transition relation may be written as $\delta(\Sigma, \Lambda, \Sigma')$.

Binary decision diagrams (BDDs) are used to represent the characteristic formulas efficiently. The description of BDDs is delayed to Section~\ref{sec:back_bdd}.

\section{Fixed Points}
\label{sec:fixed_points}

\subsection{Syntax}

This section defines a logic with fixed points capable of expressing greatest and least solutions of fixed point equations $X = f(X)$ where $f$ is a monotone function. The set of formulas in this logic is defined as follows:

Let $P$ be a set of propositions and $V$ be a set of variables. Then

\begin{itemize}
    \item each proposition $p \in P$ is a formula
    \item if $\phi$ and $\psi$ are formulas then $\phi \wedge \psi$ is a formula
    \item if $\phi$ is a formula then $\neg \phi$ is a formula
    \item if $\phi$ is a formula and $Z$ a variable then $\nu Z.\phi$ is a formula provided that every free occurrence of $Z$ in $\phi$ occurs under an even number of negations
    \item if $\phi$ is a formula and $Z$ is a variable then $\forall Z. \phi$ is a formula
\end{itemize}

\noindent Given these definitions, we also have:
\begin{itemize}
    \item $\phi \vee \psi$ meaning $\neg (\phi \wedge \psi)$
    \item $\mu Z. \phi$ meaning $\neg \nu Z. \neg \phi [Z := \neg Z]$ where $\phi[Z := \neg Z]$ means substituting $\neg Z$ for all free occurrences of $Z$ in $\phi$
    \item $\exists Z. \phi$ meaning $\neg \forall Z. \neg \phi$
\end{itemize}

\subsection{Semantics}
\label{sec:musem}

Given the tuple $\langle S, F \rangle$ where
\begin{itemize}
    \item S is the set of states
    \item $F : P \rightarrow 2^S$ maps each proposition to the set of states where the proposition is true
\end{itemize}

\noindent A \mucalc formula is interpreted as follows:
\begin{itemize}
    \item $p$ holds in the set of states $F(p)$
    \item $\phi \wedge \psi$ holds in the set of states where both $\phi$ and $\psi$ hold
    \item $\neg \phi$ holds in every state where $\phi$ does not hold 
    \item $\nu Z. \phi$ holds in any set of states $T$ such that when the variable $Z$ is set to $T$ in $\phi$ then $\phi$ holds for all of $T$. It is the greatest fixpoint of $\phi$.
    \item $\forall X. \phi$ holds when $\phi$ holds for all possible values of $X$.
\end{itemize}

\subsection{From \mucalc formulas to algorithms}

It is straightforward to convert a \mucalc formula into an algorithm that returns the set of states for which the formula holds.

Greatest and least fixed points are computed by iteration. To compute the greatest fixed point of a function $f(x)$ i.e. $\nu X. f(X)$ we iterate $f$ starting with the universal set. As $f$ is monotonic, the result is guaranteed to shrink or stay the same on each iteration. Furthermore, if the set of states, $S$ is finite, this iteration must eventually converge to some set as $S$ being finite prevents the result from shrinking forever. 

The algorithm for computing the set of states for which a \mucalc formula holds is given in Algorithm~\ref{a:mu_semantics}. It assumes the existence of an abstract set datatype that supports set union, complementation and equality checking.

\begin{algorithm}
\begin{algorithmic}

\Function{MuSemantics}{$\phi$}
    \If {$\phi = p$} 
        \State\Return $F(p)$
    \ElsIf {$\phi = \psi \vee \rho$}
        \State\Return $\Call{MuSemantics}{\psi} \cup \Call{MuSemantics}{\rho}$
    \ElsIf {$\phi = \neg \psi$}
        \State\Return $S - \Call{MuSemantics}{\psi}$
    \ElsIf {$\phi = \forall X. \psi$}
    \State\Return $\{ s \in S \; | \; \forall x. \; s \in \Call{MuSemantics}{\psi[X:=x]} \}$
    \ElsIf {$\phi = \nu X. \psi$}
        \State $Z \gets S$
        \Loop
            \State $Z' \gets \Call{MuSemantics}{\psi[X:=Z]}$
            \If {$Z' = Z$}
                \State\Return $Z$
            \EndIf
            \State $Z \gets Z'$
        \EndLoop
    \EndIf
\EndFunction

\end{algorithmic}
\caption{MuSemantics, given a \mucalc formula, returns the set of states that satisfy the formula.}
\label{a:mu_semantics}
\end{algorithm}

\section{Solving Games}
\label{sec:intro_solving}

Given a game and an objective there are two questions we can ask:
\begin{itemize}
    \item can player~1 win?
    \item if so, what is the strategy for player~1 and, if not, what is the counterexample strategy for player~2
\end{itemize}

I present algorithms to answer these questions in this section. I begin with the simplest game, the reachability game, and progress to GR(1) games as are used in Termite.

\subsection{Controllable predecessor}
\label{sec:back_cpre}

All of the algorithms for games I will be describing use a function called the \emph{controllable predecessor} (abbreviated \cpre). \cpre\ is a function from a target set of game states ($2^S$) called the \emph{target set} to another set of game states. Given a set $T$, $CPre(T)$ returns the set of states from which player 1 can force execution into $T$ in one step. 

The exact details of \cpre\ depend on the type of game being solved. Here it is considered to be a parameter to the game solving algorithms. The only property of $CPre$ that the game solving algorithms require is that it is monotonic, i.e.\ if $X \subseteq Y$ then $CPre(X) \subseteq CPre(Y)$. Clearly, any reasonable \cpre\ function will have this property.

In the following sections I describe the controllable predecessor for turn based games as well as the more complicated type of games used in Termite.

\subsubsection{Turn based controllable predecessor}

\begin{multline}
CPre(X) = \tau_1 \cap \{x | \exists l. \langle x, l, x' \rangle \in \delta \rightarrow x' \in X\} \\ \cup \tau_2 \cap \{x | \langle x, l, x' \rangle \in \delta \rightarrow x' \in X \}
\label{eqn:turn_cpre}
\end{multline}

The controllable predecessor for turn based games, given by Equation~\ref{eqn:turn_cpre}, returns the subset of $\tau_1$ where there exists a label which player~1 can choose to take execution into $X$ together with the subset of $\tau_2$ where all labels which player~2 can choose take execution into $X$. 

\begin{figure}[t]
\centering
\includegraphics[width=0.2\linewidth]{diagrams/turnCpre.pdf}
\caption{Turn based controllable predecessor}
\label{fig:turn_cpre}
\end{figure}

This is illustrated in Figure~\ref{fig:turn_cpre}. Assume that the two dark states are winning and they form the set $X$ passed to $CPre$. Solid lines represent controllable transitions and dashed lines represent uncontrollable transitions. $CPre$ returns state $s1$ in the winning set because it is a controllable state and there exists a transition into a winning state. State $s2$ is also winning because it is an uncontrollable state and all outgoing transitions go to winning states. Lastly, $s3$ is \emph{not} winning because it is uncontrollable and one of its outgoing transitions does not lead to a winning state.

We can convert the turn based controllable predecessor to symbolic form (Section~\ref{sec:intro_symb}) as shown in Equation~\ref{eqn:cpre_symb}. 

\begin{equation}
CPre(X) = \tau_1 \wedge \exists \symLabelVars. \forall \symStateVars'. \delta \rightarrow X' \vee \tau_2 \wedge \forall \symLabelVars. \forall \symStateVars'. \delta \rightarrow X' 
\label{eqn:cpre_symb}
\end{equation}

\noindent where $X'$ is $X$ with the variables in $\Sigma$ renamed to the corresponding variable in $\Sigma'$ and $\tau_1$, $\tau_2$ and $\delta$ are given symbolically. Additionally, quantifiers are extended to set of variables e.g. $\forall \symStateVars$ means `for all values of all variables in $\symStateVars$'.

\subsubsection{Termite's controllable predecessor}
\label{sec:termite_cpre}

\paragraph{Concurrent Games}

Games where there are states in which both player~1 and player~2 have moves are called \emph{concurrent games}. Concurrent games differ from simpler turn based games in that in each state both players get to pick a label and the next state that the game transitions to is some (possibly non-deterministic) function, $\lambda$, of both of those labels. Turn based games are a special case of concurrent games where in player~i states (a concept that does not generally exist in concurrent games) $\lambda$ only depends on the label played by player~i and the other player's label is ignored. 

\paragraph{Termite's controllable predecessor}

In Termite, however, the concurrent game is almost as simple as a turn based game. Labels, not states, are classified as controllable or uncontrollable. $\lambda$ chooses the effective label non-deterministically. This means that while player~1 may choose a label in any state, there is no guarantee that it will be played. There is, however, a fairness guarantee that each player eventually gets a turn that will be dealt with later.

This non-determinism is simulated with the input variable \code{controllable}. This variable is always chosen non-deterministically. The (now deterministic) $\lambda$ function picks the player~1 chosen label if \code{controllable} is $True$ and it picks the player~2 chosen label otherwise.

Disregarding fairness for now, given a target state $X$, a state $s$ is defined to be winning if both:
\begin{enumerate}
    \item there exists a controllable label originating from $S$ such that all transitions with this label lead to $X$, and
    \item all uncontrollable transitions with any label originating from $S$ lead to $X$
\end{enumerate}
\noindent are simultaneously true. 

Condition~1 is captured by the function $CpreC$ given symbolically in Equation~\ref{eqn:termite_cpre_c}. It returns the set of states from which there exists a controllable label such that all transitions with this label lead to a state in the target set $X$.

\begin{equation}
    CpreC(X) =  \exists L. controllable \land \forall N. Trans(S, L, N) \rightarrow X(N)
    \label{eqn:termite_cpre_c}
\end{equation}

Condition~2 is captured by the function $CpreU$ given symbolically in Equation~\ref{eqn:termite_cpre_u}. It returns the set of states from which all transitions with uncontrollable labels lead to a state in $X$.

\begin{equation}
    CpreU(X) =  \forall L. \neg controllable \rightarrow \forall N. Trans(S, L, N) \rightarrow X(N)
    \label{eqn:termite_cpre_u}
\end{equation}

The final controllable predecessor, $Cpre$, given symbolically in Equation~\ref{eqn:termite_cpre} returns the set of states for which both conditions are satisfied.

\begin{equation}
    Cpre(X) =  CpreC(X) \land CpreU(X)
    \label{eqn:termite_cpre}
\end{equation}

\begin{figure}[t]
\centering
\includegraphics[width=0.4\linewidth]{diagrams/concurrentCpre.pdf}
\caption{Concurrent controllable predecessor}
\label{fig:concurrent_cpre}
\end{figure}

This is illustrated in Figure~\ref{fig:concurrent_cpre}. Again, assume that the two dark states are winning and they form the set $X$ passed to $CPre$. $CPre$ returns state $s1$ in the winning set because there exists a controllable transition into the winning set and all uncontrollable transitions also lead to the winning set. State $s2$ is \emph{not} winning because it does not have a controllable transition into the winning set. Lastly, $s3$ is \emph{not} winning because there exists an uncontrollable transition to a non-winning state.

\subsection{Solving safety and reachability games}
\label{sec:back_solving_reach}

We start with reachability as it is the simplest type of objective. Games are solved by finding the set of states from which player~1 can win, called the \emph{winning region} and denoted \win. If the winning region contains the set of initial states, then we know that player~1 can win from any state in the initial set and thus can win the game.

According to Equation~\ref{eqn:reachobj}, a state is winning in a reachability game if there is some finite $i$ such that we can guarantee that after $i$ rounds of the game, execution will have, at least once, entered a state in $\reachobj$. 

We can define the winning region inductively. It is obviously possible to reach the set $\reachobj$ from $\reachobj$ in 0 steps as we are already there. This is the base case. It is also possible to reach $\reachobj$ from $x \in S$ in $N + 1$ steps or fewer iff there exists $Y\subseteq 2^S$ such that it is possible to reach $\reachobj$ from all of $Y \subseteq 2^S$ in $N$ steps or fewer and $x \in CPre(Y)$.

This suggests an algorithm to find the winning region. We start with $\reachobj$, apply \cpre\ to get the states winning in 1 step, combine with $\reachobj$ again to get the states reachable in 1 step or less, and then repeat. After $N$ iterations, we find the states winning in $N$ or less steps. Two questions remain: 

\begin{itemize}
    \item An algorithm must terminate, so, when should we stop iterating?
    \item After termination, has the algorithm found all the winning states?
\end{itemize}

We denote the set of states from which it is possible to reach \reach\ in $N$ or less steps $W_N$. Observe that $W_{N+1} \supseteq W_N$. So, on each iteration, we either grow the winning set or it remains the same. Also observe that the set $S$ is finite, which means that $2^S$ is also finite. As set inclusion is a transitive relation, we cannot grow the winning set forever, so eventually we must reach a fixed point of the \cpre\ function. 

A more formal proof of termination is based in the Knaster-Tarski theorem \cite{tarski1955}. The power set of $S$ can be ordered by set inclusion to obtain a complete lattice with supremum $S$ and infimum $\emptyset$. $f(X) = \cpre\ (X \cup REACH)$ is an order preserving function, so by the Knaster-Tarski theorem the set of fixed points of $f$ is also a complete lattice. Thus there exists a greatest and least fixed point (as the lattice is complete). The least fixed point of $f$ is clearly obtained by iteration starting from the least element of the lattice, ie. $\emptyset$. 

Thus, we will eventually reach a fixed point, and, this is when we should stop iterating as further iterations will not change the winning set. Furthermore, we know that after any finite number $N$ of iterations where $N$ is greater than the number of iterations required to reach the fixed point, the winning region will remain $WIN$. Thus $WIN_N = WIN$ and we have found all winning states.

Finally, to answer the question of whether the game is winning for player~1, we check if the winning region contains the initial state set. If it does, we return \emph{Yes}; otherwise, we return \emph{No}. The algorithm is given in Algorithm~\ref{a:reach}. 

\begin{algorithm}[t]
\begin{algorithmic}

\Require A set of target states $\reachobj \subseteq S$, an initial set of states $I$ and a monotonic controllable predecessor $CPre$.
\Ensure  {\it Yes} if $I \subseteq \mathit{\reachFun(T, Cpre)}$ and {\it No} otherwise.

\Function{\reachFun}{$\reachobj, I, CPre$}
    \State $Y \gets \varnothing$
    \Loop
        \State $Y' \gets CPre(Y \cup \reachobj)$
        \If {$Y' = Y$} 
            \If {$Y \subseteq I$}
                \State\Return Yes
            \Else
                \State\Return No
            \EndIf
        \EndIf
        \State $Y \gets Y'$
    \EndLoop
\EndFunction

\end{algorithmic}
\caption{Solving a reachability game}
\label{a:reach}
\end{algorithm}

The equivalent \mucalc (Section~\ref{sec:fixed_points}) formula is given in Equation~\ref{eqn:mu_reach}. 

\begin{equation}
    \mathit{\reachFun}(T) = \mu Y. CPre(Y \vee T)
\label{eqn:mu_reach}
\end{equation}

We can translate this to a symbolic (Section~\ref{sec:intro_symb}) Algorithm using characteristic functions instead of explicit sets by replacing conjunction and disjunction with set intersection and union. The symbolic reachability algorithm is given in Algorithm~\ref{a:symb_reach}.

\begin{algorithm}
\begin{algorithmic}

\Require The characteristic function of the set of target states $\reachobj \subseteq S$, the characteristic function of the initial set of states $I$ and a monotonic controllable predecessor \cpre\ that operates on characteristic functions.
\Ensure  {\it Yes} if $I \subseteq REACH(T, CPre)$ and {\it No} otherwise.

\Function{Reach}{$\reachobj, I, CPre$}
    \State $Y \gets False$
    \Loop
        \State $Y' \gets CPre(Y \vee \reachobj)$
        \If {$Y' = Y$} 
            \If {$Y \rightarrow I$}
                \State\Return Yes
            \Else
                \State\Return No
            \EndIf
        \EndIf
        \State $Y \gets Y'$
    \EndLoop
\EndFunction

\end{algorithmic}
\caption{Solving a reachability game symbolically}
\label{a:symb_reach}
\end{algorithm}

Safety games are the dual of reachability games and are also solved by iterating the controllable predecessor. The \mucalc formula for computing the winning region is given in Equation~\ref{eqn:mu_safe} and the algorithm can be deduced from this using Algorithm~\ref{a:mu_semantics}.

\begin{equation}
\mathit{\safeFun}(T) = \nu Y. CPre(Y \wedge T)
\label{eqn:mu_safe}
\end{equation}

\subsection{\buchi}

To solve a \buchi\ game, we first find the set from which we can reach the goal once as we do for a reachability game. Then, we use this set to find the set from which we can reach the goal twice, three times, and so on until we get to another fixed point. 

Imagine we have solved the reachability game $R = \reachFun(T)$ where $T$ is the \buchi\ target set and $R$ is the winning region. Then $V = R \wedge T$ is a subset of the goal from which player~1 can reach the goal one more time. Computing $W = \reachFun(V)$ gets us the set of states from which we can reach the goal twice. Iterating this procedure will eventually lead to a fixed point as $\reachFun$ is a monotonic function.

This fixed point is the set of states from which we can reach the goal any number of times. Thus, it is the winning set of the \buchi\ game. The \mucalc formula is given in Equation~\ref{eqn:mu_buchi} and the algorithm to solve \buchi\ games can be deduced from this using Algorithm~\ref{a:mu_semantics}.

\begin{equation}
    \mathit{\buchiFun}(T) = \nu X. \mu Y. CPre(Y \vee (X \wedge T))
\label{eqn:mu_buchi}
\end{equation}

\subsection{Generalised \buchi}

Solving a generalised \buchi\ game is similar to a \buchi\ game except that we find the set from which we can reach any goal once, then any goal twice, etc. The algorithm is a small modification to the \buchi\ algorithm and is given in Algorithm~\ref{alg:gen_buchi}. The equivalent \mucalc formula is given in Equation~\ref{eqn:mu_genbuchi}.

\begin{algorithm}[t]
\begin{algorithmic}
\Function{Generalised\_Buchi}{$T$, $CPre$}
\State $X \gets S$
\Loop
\State $X' \gets S$

\For{\textbf{each} G in Goals}
\State $X' \gets X' \cap \Call{\reachFun}{X \cap G}$
\EndFor

\If {$X' = X$} 
\State\Return $X$\EndIf
\State $X \gets X'$

\EndLoop
\EndFunction
\end{algorithmic}
\caption{Solving a generalised \buchi\ game}
\label{alg:gen_buchi}
\end{algorithm}

\begin{equation}
    \mathit{\genBuchiFun}(Goals) = \nu X. \bigwedge_{G \in Goals} \mu Y. CPre(Y \vee (X \wedge G))
\label{eqn:mu_genbuchi}
\end{equation}

\subsection{GR(1)}

Next, fairness is added. Consider a fair reachability game. An unfair region is a region that we can assume execution will leave, regardless of the loops it contains. The controllable predecessor is modified to create a fair controllable predecessor that takes this into account. Intuitively, the algorithm considers a set of unfair states to be winning if the only way out leads to an already winning state. To compute this set of states, we play a variation of a safety game where we can win if we stay indefinitely within the unfair set or upon exiting the unfair set we are immediately in the target set $T$. The procedure for the fair controllable predecessor is given in Algorithm~\ref{a:fair_cpre} and the equivalent \mucalc formula is given in Equation~\ref{eqn:mu_fair}. 

\begin{algorithm}[t]
\begin{algorithmic}
\Function{\fairCpreFun}{$CPre$, $\phi$, $T$}
\State $Z \gets S$
\Loop
\State $Z' \gets \Call{CPre}{Z \cap \phi \cup T}$
\If {$Z' = Z$} 
\State\Return $Z$\EndIf
\State $Z \gets Z'$
\EndLoop
\EndFunction
\end{algorithmic}
\caption{The fair controllable predecessor}
\label{a:fair_cpre}
\end{algorithm}

\begin{equation}
    \mathit{\fairCpreFun}(F, T) = \nu Z. CPre((\neg F \wedge Z) \vee T)
\label{eqn:mu_fair}
\end{equation}

Using $\mathit{\fairCpreFun}$ as the controllable predecessor operator in the reachability algorithm (Algorithm~\ref{a:reach}) yields the fair reachability algorithm. Finally, if we combine the \buchi\ game with the fair controllable predecessor we get a GR(1) game. The procedure is given in Algorithm~\ref{a:gr1} and the equivalent \mucalc formula is given in Equation~\ref{eqn:mu_gr1}.

\begin{algorithm}[t]
\begin{algorithmic}
\Function{\grWin}{$CPre$, $T$}
\State\Return \Call{\buchiFun}{$T$, \fairCpreFun(CPre)}
\EndFunction
\end{algorithmic}
\caption{GR(1) game}
\label{a:gr1}
\end{algorithm}

\begin{multline}
    \grWin(Goals, Fairs) = \\ \nu X. \bigwedge_{G \in Goals} \mu Y. \bigvee_{F \in Fairs} \nu Z. CPre((\neg F \wedge Z) \vee (G \wedge X) \vee Y)
\label{eqn:mu_gr1}
\end{multline}

\section{Strategies and Counterexamples}
\label{sec:strat_and_cex2}

\subsection{Extracting strategies}

\subsubsection{Reachability}

Once we have solved a game and determined that it is winning, we can extract a strategy. In driver synthesis, the strategy is used to generate the driver. A strategy for a reachability game is a relation between states and labels for player~1 to play such that if player~1 sticks to this strategy, the game will eventually end up in the goal. Strategy extraction requires a straightforward modification to the game solving algorithm.

When solving a reachability game, we discover the sets of states for which we can force execution into the goal in 1 step, 2 steps, etc. When extracting a strategy for a reachability game we need to record, for each iteration, what labels we had to play to get one step closer to the goal. The algorithm is given in Algorithm~\ref{alg:reach_strat}. 

The strategy relation is initialised to the empty set on line~\ref{l:rs:init}. Then, we perform an iteration of the controllable predecessor. This time we also use \textsc{CPre\_Strat} on line~\ref{l:rs:cs}, which computes a relation between the winning states discovered so far and the labels that take execution from these newly discovered states one step closer to the goal.

On each iteration we combine this strategy for the newly discovered states with the strategy for the previously discovered states. We are careful on line~\ref{l:rs:as} not to add new labels for states that have already been discovered to ensure that the labels take us towards the goal. We iterate until the winning region reaches a fixed point as before. In the end, the strategy relates each state in the final winning region to a set of labels that take the game one step closer to the goal.

\textsc{CPre\_Strat} is a parameter to the strategy extraction algorithm in the same way as \textsc{\cpre} is to the game solving algorithm. Its definition depends on the exact details of the game. For completeness, the definition of \textsc{CPre\_Strat} for turn based games is given in Equation~\ref{eqn:cpre_strat}. 

\begin{equation}
    CPre\_Strat(X) = \{\langle x, l \rangle | x \in \tau_1 \wedge (\langle x, l, x' \rangle \in \delta \rightarrow x' \in X)\}
    \label{eqn:cpre_strat}
\end{equation}

It returns a set of $\langle state, label \rangle$ pairs where the state belongs to the \pone\ controllable set such that if the label is played, execution ends up in the set $X$, the argument to the function.

\begin{algorithm}[t]
    \begin{algorithmic}[1]

\Function{Reach\_Strat}{$\reachobj, CPre, CPre\_Strat$}
\State $Y \gets \varnothing$ \label{l:rs:init}
\State $STRAT \gets \varnothing$
    \Loop
        \State $Y' \gets CPre(Y \cup \reachobj)$
        \If {$Y' = Y$} 
            \State\Return $(Y, STRAT)$
        \EndIf
        \State $STRAT' \gets CPre\_Strat(Y \cup \reachobj)$ \label{l:rs:cs}
        \State $STRAT \gets STRAT \cup \{\langle s, l \rangle | \langle s, l \rangle \in STRAT' \wedge s \notin Y\}$  \label{l:rs:as}
        \State $Y \gets Y'$
    \EndLoop
\EndFunction

\end{algorithmic}
\caption{Extracting a strategy for a reachability game}
\label{alg:reach_strat}
\end{algorithm}

\subsubsection{\buchi}

Like a reachability strategy, a strategy for a \buchi\ game must ensure that we eventually get to the goal. However, it must also ensure that once we get to the goal it is still possible to reach the goal again. 

If we find a reachability strategy for the intersection of the goal set and the winning region, then when we follow this strategy, we are guaranteed to reach the goal once and then be able to reach it again by following the same strategy because we remain in the winning region. Thus, the algorithm for finding the strategy for a \buchi\ game is to find the winning region of the game and then compute the reachability strategy for the intersection of the goal and the winning region.

The algorithm for computing the strategy in a \buchi\ game is given in Algorithm~\ref{alg:buchi_strat}. It simply computes the \buchi\ winning region on line~\ref{l:bs:rw} and then computes the strategy to reach the intersection of the winning region and the goal set on line~\ref{l:bs:rs}.

\begin{algorithm}[t]
\begin{algorithmic}[1]

\Function{Buchi\_Strat}{$\buchiobj$, $\mathit{\cpre}$, $\mathit{\cpreStrat}$}
    \State $win \gets \Call{Buchi}{\buchiobj}$ \label{l:bs:rw}
    \State \Return \Call{Reach\_Strat}{$win \cap \buchiobj$, $\mathit{\cpre}$, $\mathit{\cpreStrat}$} \label{l:bs:rs}
\EndFunction

\end{algorithmic}
\caption{Extracting a strategy for a \buchi\ game}
\label{alg:buchi_strat}
\end{algorithm}

\subsubsection{Generalised \buchi}
\label{sec:genbuch}

A generalised \buchi\ strategy must ensure that we can always get to any of the goals. If we compute, for each goal, the reachability strategy for the intersection of that goal and the generalised \buchi\ winning region, we get a strategy that takes us to that goal and, by keeping execution in the winning region, ensures that we can reach any of the other goals using their strategies. 

Thus, a strategy for a generalised \buchi\ game is a set of strategies, one for each goal, that we must play in a round robin manner to ensure that each goal is eventually reached. The finite state required to ensure that the strategies are played in a round robin order is the finite state that the generalised \buchi\ strategy requires as discussed in Section~\ref{sec:strat_and_cex}. This, for example, could be a counter that that loops through the goals and is incremented each time the current goal is reached.

The algorithm for computing the strategy in a generalised \buchi\ game is given in Algorithm~\ref{alg:gen_buchi_strat}. It first computes the winning region of the generalised \buchi\ on line~\ref{l:gbs:wr} and then it computes a strategy to reach the intersection of this and each goal on line~\ref{l:gbs:rs}.

\begin{algorithm}
\begin{algorithmic}[1]

\Function{Gen\_Buchi\_Strat}{$\genbuchiobj$}
\State $win \gets \Call{Generalised\_Buchi}{\genbuchiobj}$ \label{l:gbs:wr}
    \State $strats \gets [\;]$
    \For{\textbf{each} $G \in \genbuchiobj$}
        \State $strats \gets strats \; \oplus \; \Call{Reach\_Strat}{win \cap G}$ \label{l:gbs:rs}
    \EndFor
    \State \Return $strats$
\EndFunction

\end{algorithmic}
\caption{Extracting a strategy for a generalised \buchi\ game}
\label{alg:gen_buchi_strat}
\end{algorithm}

\subsubsection{Fairness}

To compute strategies for fair variants of reachability, \buchi\ and GR(1) games we introduce a modified controllable predecessor that takes fairness into account and returns winning moves along with winning states, called \code{CPre\_Strat\_Fair}. This modified controllable predecessor, in turn, is parameterised by the CPre and CPre\_Strat of the underlying game.

The fair controllable predecessor must ensure that we can reach the target set assuming that an unfair condition is not forever true. Conceptually, it tries to keep execution within an unfair region for which the only way out takes us a step closer to the goal. 

The algorithm for computing the strategy in a fair reachability game is given in Algorithm~\ref{alg:fair_cpre_strat}. It essentially solves a safety game for $\neg\phi$ with the exception that it is possible to leave safe regions as long as you enter $T$. When a fixed point is reached on line~\ref{l:fcp:st} it uses \code{CPre\_Strat} to compute a strategy to either stay within the computed unfair region or enter the target set. This strategy is guaranteed to reach the target set as long as fairness is not violated. This function may be used as a drop-in replacement for \code{CPre\_Strat} when the game is required to be fair.

\begin{algorithm}
\begin{algorithmic}[1]

\Function{Fair\_CPre\_Strat}{$CPre, CPre\_Strat, \phi, T$}
    \State $Z \gets U$
    \Loop
        \State $Z' \gets \Call{CPre}{Z \wedge \neg\phi \vee T}$
        \If {$Z' = Z$} 
        \State\Return $\Call{CPre\_Strat}{Z \wedge \neg\phi \vee T}$ \label{l:fcp:st}
        \EndIf
        \State $Z \gets Z'$
    \EndLoop
\EndFunction

\end{algorithmic}
\caption{Fair controllable predecessor strategy extraction}
\label{alg:fair_cpre_strat}
\end{algorithm}

\subsubsection{GR(1)}

Strategies for GR(1) games, as used in Termite, can be computed using Algorithm~\ref{alg:gen_buchi_strat} instantiated with the fair controllable predecessor, Algorithm~\ref{alg:fair_cpre_strat}.

\subsection{Extracting counterexamples}

Counterexamples are computed by solving the complement game and extracting the strategy.

\subsubsection{Reachability}

The complement of a reachability game is a safety game with negated objective. This can be seen by complementing the \mucalc formula for the winning region, repeated below for convenience.

\begin{equation}
    \mathit{REACH}(T) = \mu Y. CPre_1(Y \vee T)
\end{equation}

\begin{equation}
    \neg\mathit{REACH} = \neg\nu Y. CPre_2(Y \wedge \neg T) = \mathit{SAFE}(\neg T) 
\end{equation}

Thus, the counterexample strategy for a reachability game is the strategy for a safety game with complemented objective and the other player's controllable predecessor. 

\subsubsection{GR(1)}

The formula for the complement of a GR(1) game is given below. Its complement is given in Equation~\ref{eqn:mu_gr1} for comparison.

\begin{multline}
    \neg GR1(Goals, Fairs) = \\ \mu X. \bigvee_{G \in Goals} \nu Y. \bigwedge_{F \in Fairs} \mu Z. CPre_2((F \vee Z) \wedge (\neg G \vee X) \wedge Y)
\end{multline}

Intuitively, to ensure that player~1 cannot win a GR(1) game, player~2 must ensure that there is at least one goal that is only reached finitely many times, and each fairness condition is visited infinitely many times. 

\section{Binary Decision Diagrams}
\label{sec:back_bdd}

A binary decision diagram is an efficient data structure for manipulating large propositional formulas. They may be used to efficiently implement symbolic algorithms (Section~\ref{sec:intro_symb}). They are the symbolic data structure that is used in Termite~\cite{Ryzhyk_WKLRSV_14}.

\subsection{Binary decision trees}

\begin{figure}[t]
\centering
\includegraphics[width=0.5\linewidth]{diagrams/binaryDecisTree.pdf}
\caption{A binary decision tree for $x \vee y$}
\label{fig:decis_tree}
\end{figure}

Figure~\ref{fig:decis_tree} shows a decision tree for the disjunction of two variables. The root node represents the entire function. The internal nodes represent variables and the leaf nodes, or terminal nodes, represent the outcome of the function. Terminal nodes are labelled either True or False. Given a valuation of X and Y, we can evaluate the function by starting at the root and taking the solid edge if the variable represented by the node is assigned to True in the valuation and taking the dashed edge if the value is assigned to False. 

For example, in Figure~\ref{fig:decis_tree}, for the valuation $x=True$ and $y=False$, we start at the root node which is labelled x as x is this node's decision variable. Variable $X$ is assigned to True so we follow the solid edge to the next decision node which is labelled $Y$. $Y$ is assigned to false so we take the dashed edge and arrive at a terminal node whose value is 1, meaning that the function evaluates to 1 for this variable valuation.

\subsection{Ordered binary decision trees}

If the order in which the variables appear along all paths starting from the root node and ending at a terminal node are the same, then the decision tree is called an ordered decision tree. The decision tree in Figure~\ref{fig:decis_tree} is ordered.

\subsection{Reduced ordered binary decision diagrams}

\begin{figure}[t]
\centering
\includegraphics[width=0.5\linewidth]{diagrams/bdd.pdf}
\caption{A binary decision diagram}
\label{fig:bdd}
\end{figure}

A reduced ordered binary decision diagram (from now on, just BDD) is created by sharing subtrees as much as possible within an ordered binary decision tree.

In particular: 
\begin{itemize}
    \item Terminal nodes with the same label are merged. This means there are only two terminal nodes: True and False.
    \item Internal nodes with the same children are merged.
    \item Nodes with two identical children are removed and all incoming nodes are redirected to the child.
\end{itemize}

Figure~\ref{fig:bdd} is an example of a BDD.

\subsection{Canonicity}
Given a variable ordering, reduced ordered binary decision diagrams are a canonical representation of a function. This means that given a function $f$ of some set $S$ of variables, another function $g$ that evaluates to the same value for each valuation of the variables in $S$ will be represented by exactly the same BDD.

In practice, one uses a BDD library such as CUDD \cite{cudd} to build and manipulate BDDs. CUDD keeps track of all BDDs and subtrees within the BDDs that have been created and reuses these to ensure that all BDDs remain in reduced form. This, along with canonicity, means that BDD equivalence can be checked in constant time simply by checking pointer equality of the two BDDs.

\subsection{Complement arcs}

Arcs may have a complement attribute. The function represented by an arc is the function of the node that it points to, unless it is a complement arc, in which case it is the complement of the function of the node that it points to.

Use of complement arcs has two important advantages:
\begin{itemize}
    \item Decreased memory requirements
    \item Complementation can be done in constant time, allowing De Morgan's laws to be used freely
\end{itemize}

Additionally, it can be shown that, if only the else arcs of internal nodes are ever complemented then canonicity can be preserved.

\subsection{Conjunction and disjunction}

BDDs are not usually built as decision trees and then reduced. Instead, they are built from the bottom up, starting with the terminal and variable nodes and combining these using conjunction, disjunction and negation.

Conjunction and disjunction are computed using a straightforward recursive algorithm that will not be given here, see \cite{Bryant_86}. An important result is that, in the worst case, the procedure runs in time proportional to the product of the sizes of the two input BDDs. Furthermore, the size of the resulting BDD may be equal to the product of the sizes of the two input BDDs in the worst case. A strength of BDDs, however, is that this worst case rarely happens in practice. 

\subsection{Function composition and quantification}

Function composition is where a BDD representing some function is substituted for a variable in another BDD.

Given a function $f(x_1,\cdots,x_n)$, existential quantification of $f$ with respect to the Boolean variable $x_i$ is defined as $\exists x_i.\ f = f_{x_i} \vee f_{\overline{x_i}}$ and universal quantification of $f$ with respect to $x_i$ as $\forall x_i.\ f = f_{x_i} \wedge f_{\overline{x_i}}$.

Quantifications of the same type commute, so quantification with respect to a set of variables is well defined. 

\subsection{Variable ordering}

The number of nodes in a BDD depends drastically on the ordering chosen for the variables. Therefore, the space occupied by the BDDs and the time spent performing operations on them also depends on the variable ordering. This directly affects the performance of game solving algorithms that use BDDs as the symbolic data structure. 

Optimal variable orderings may be found using exact algorithms, but these are prohibitively expensive for BDDs with more than a few nodes. In practice heuristics are used which produce good, but not optimal orderings. One such heuristic is Rudell's sifting algorithm \cite{Rudell_1993}.

The CUDD BDD package performs \emph{dynamic variable ordering}, which means that once the number of BDD nodes grows past a certain threshold, the package automatically performs the requested reordering algorithm on all BDDs that exist in the manager. Dynamic variable ordering is critical to the performance of game solving algorithms that utilise BDDs and therefore it is always enabled in Termite.

